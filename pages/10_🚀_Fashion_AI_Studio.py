import streamlit as st
import google.generativeai as genai
from PIL import Image, ImageOps
import io
import sys
import os
import base64

# --- 0. å¼•å…¥é—¨ç¦ç³»ç»Ÿ ---
sys.path.append(os.path.abspath('.'))
try:
    import auth
    if not auth.check_password(): st.stop()
except ImportError:
    pass 

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="Fashion AI Studio", page_icon="ğŸš€", layout="wide")

# è‡ªå®šä¹‰ CSS (å¤åˆ» React App çš„æš—è‰²è°ƒé£æ ¼)
st.markdown("""
<style>
    .stApp {
        background-color: #0f0f13;
        color: #e2e8f0;
    }
    .stButton button {
        width: 100%; 
        border-radius: 12px; 
        font-weight: bold;
        background-image: linear-gradient(to right, #4f46e5, #9333ea);
        border: none;
        color: white;
        padding: 12px;
    }
    .stButton button:hover {
        background-image: linear-gradient(to right, #4338ca, #7e22ce);
        color: white;
    }
    .stTextInput input, .stTextArea textarea {
        background-color: #1e293b;
        color: white;
        border: 1px solid #334155;
        border-radius: 8px;
    }
    .step-card {
        background-color: #1e293b;
        padding: 20px;
        border-radius: 16px;
        border: 1px solid #334155;
        margin-bottom: 20px;
    }
    h1, h2, h3 { color: #f8fafc !important; }
    .mode-btn-selected { border: 2px solid #6366f1; background-color: #312e81; color: white; padding: 10px; border-radius: 8px; text-align: center; cursor: pointer; }
    .mode-btn { border: 1px solid #334155; background-color: #1e293b; color: #94a3b8; padding: 10px; border-radius: 8px; text-align: center; cursor: pointer; }
</style>
""", unsafe_allow_html=True)

# --- 2. é…ç½® ---
if "GOOGLE_API_KEY" not in st.secrets:
    st.error("âŒ è¯·é…ç½® GOOGLE_API_KEY")
    st.stop()

genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])

# TS ä»£ç ä¸­ä½¿ç”¨çš„æ¨¡å‹ (ç»è¿‡éªŒè¯å¯ç”¨çš„æ¨¡å‹)
MODEL_NAME = "gemini-2.5-flash-image"

# --- 3. æ ¸å¿ƒé€»è¾‘å¤åˆ» (Porting geminiService.ts) ---

def pil_to_bytes(img: Image.Image, format="PNG") -> bytes:
    """å°† PIL å›¾ç‰‡è½¬ä¸ºå­—èŠ‚æµ"""
    buf = io.BytesIO()
    img.save(buf, format=format)
    return buf.getvalue()

def resize_for_context(img: Image.Image, max_dim=2048) -> Image.Image:
    """
    å¤åˆ» TS: resizeForContext
    é™åˆ¶å›¾ç‰‡æœ€å¤§å°ºå¯¸ï¼Œä¿æŒæ¯”ä¾‹
    """
    w, h = img.size
    if w > max_dim or h > max_dim:
        ratio = min(max_dim / w, max_dim / h)
        new_w = int(w * ratio)
        new_h = int(h * ratio)
        return img.resize((new_w, new_h), Image.Resampling.LANCZOS)
    return img

def extract_texture_patch(img: Image.Image) -> Image.Image:
    """
    å¤åˆ» TS: extractTexturePatch (æ ¸å¿ƒæŠ€æœ¯!)
    æå–å›¾ç‰‡ä¸­å¿ƒ 50% åŒºåŸŸä½œä¸ºçº¹ç†é”šç‚¹
    """
    w, h = img.size
    crop_w = int(w * 0.5)
    crop_h = int(h * 0.5)
    
    left = (w - crop_w) // 2
    top = (h - crop_h) // 2
    right = left + crop_w
    bottom = top + crop_h
    
    return img.crop((left, top, right, bottom))

def invert_mask_image(mask_img: Image.Image) -> Image.Image:
    """
    å¤åˆ» TS: invertMask
    åè½¬è’™ç‰ˆé¢œè‰² (å¦‚æœä½ ä¸Šä¼ çš„æ˜¯é»‘åº•ç™½ä¸»ä½“ï¼Œéœ€è¦åè½¬)
    """
    # ç¡®ä¿æ˜¯ç°åº¦æˆ–RGB
    if mask_img.mode == 'RGBA':
        r, g, b, a = mask_img.split()
        mask_img = a # ä½¿ç”¨ alpha é€šé“ä½œä¸ºè’™ç‰ˆ
    
    return ImageOps.invert(mask_img.convert("L"))

def generate_image(
    original_img: Image.Image,
    prompt: str, # Changed string to str
    mode: str,
    image_count: int = 1,
    secondary_img: Image.Image = None,
    inpainting_region: str = 'inside',
    negative_prompt: str = '' # Changed string to str
):
    """
    å¤åˆ» TS: editImage æ ¸å¿ƒé€»è¾‘
    """
    
    # 1. é¢„å¤„ç†ï¼šçº¹ç†é”šå®š (Texture Anchoring)
    # TS: const texturePatch = extractTexturePatch(sourceImgObj);
    texture_patch = extract_texture_patch(original_img)
    
    # TS: const cleanSource = await processImageStandard(originalImage, 2560, useHD);
    clean_source = resize_for_context(original_img, 2560)
    
    parts = []
    final_prompt = prompt
    
    # ç»„è£… Negative Prompt
    if negative_prompt:
        final_prompt += f"\n\nNEGATIVE CONSTRAINT (Do NOT include): {negative_prompt}."

    # æ ¹æ®æ¨¡å¼æ„å»º Payload
    if mode == 'inpainting' and secondary_img:
        # å¤åˆ» Inpainting é€»è¾‘
        final_mask = secondary_img
        if inpainting_region == 'outside':
            final_mask = invert_mask_image(secondary_img)
        
        final_mask = resize_for_context(final_mask, 2560) # ç¡®ä¿å°ºå¯¸ä¸€è‡´

        task_prompt = f"""Task: High-Fidelity Inpainting with TEXTURE ANCHORING.
Input 1: Source Image.
Input 2: Mask (White=Edit).
Input 3: TEXTURE PATCH (Ground Truth).

Instructions:
1. Modify ONLY the white areas of the mask according to: "{prompt}".
2. TEXTURE CONSISTENCY: Use Input 3 to understand the grain, sharpness, and material quality of the original image. The generated area MUST match this texture.
3. Do not produce smooth "plastic" skin or flat fabrics.
4. Keep black areas pixel-perfect.
{f'AVOID: {negative_prompt}' if negative_prompt else ''}"""

        parts.append({"text": task_prompt})
        parts.append({"inline_data": {"mime_type": "image/png", "data": base64.b64encode(pil_to_bytes(clean_source)).decode('utf-8')}})
        parts.append({"inline_data": {"mime_type": "image/png", "data": base64.b64encode(pil_to_bytes(final_mask)).decode('utf-8')}})
        parts.append({"inline_data": {"mime_type": "image/png", "data": base64.b64encode(pil_to_bytes(texture_patch)).decode('utf-8')}})

    elif mode == 'pose' and secondary_img:
        # å¤åˆ» Pose é€»è¾‘
        clean_ref = resize_for_context(secondary_img, 2560)
        
        task_prompt = f"""Task: Pose Transfer with MATERIAL PRESERVATION.
Input 1: Character (Source).
Input 2: Pose Skeleton.
Input 3: TEXTURE PATCH (Fabric/Skin Detail).

Instructions:
1. Render the character from Input 1 in the pose of Input 2.
2. MATERIAL LOCK: Input 3 proves the exact material of the clothing. You MUST preserve this specific material physics.
3. Do not hallucinate generic clothing. Use the texture from Input 3.
4. Style/Lighting: "{prompt}".
{f'AVOID: {negative_prompt}' if negative_prompt else ''}"""

        parts.append({"text": task_prompt})
        parts.append({"inline_data": {"mime_type": "image/png", "data": base64.b64encode(pil_to_bytes(clean_source)).decode('utf-8')}})
        parts.append({"inline_data": {"mime_type": "image/png", "data": base64.b64encode(pil_to_bytes(clean_ref)).decode('utf-8')}})
        parts.append({"inline_data": {"mime_type": "image/png", "data": base64.b64encode(pil_to_bytes(texture_patch)).decode('utf-8')}})

    elif mode == 'general':
        # å¤åˆ» Fusion / General Edit é€»è¾‘
        task_prompt = ""
        
        if secondary_img:
            # Fusion Mode
            clean_ref = resize_for_context(secondary_img, 2560)
            task_prompt = f"""Task: High-Fidelity Image Fusion with TEXTURE ANCHORING.
Input 1: Primary Source (Subject Context).
Input 2: Secondary Source (Background/Style).
Input 3: TEXTURE PATCH (Ground Truth - DO NOT IGNORE).

CRITICAL INSTRUCTION:
1. ANCHORING: Input 3 represents the exact pixel quality and material texture you MUST output.
2. MATERIALITY: Preserve specular highlights. Do not flatten metallic textures.
3. FUSION: Combine Input 1's Subject with Input 2's Style, but enforce Input 3's Texture quality.

Prompt: {prompt}
{f'NEGATIVE CONSTRAINTS: {negative_prompt}' if negative_prompt else ''}"""
            
            parts.append({"text": task_prompt})
            parts.append({"inline_data": {"mime_type": "image/png", "data": base64.b64encode(pil_to_bytes(clean_source)).decode('utf-8')}})
            parts.append({"inline_data": {"mime_type": "image/png", "data": base64.b64encode(pil_to_bytes(clean_ref)).decode('utf-8')}})
            parts.append({"inline_data": {"mime_type": "image/png", "data": base64.b64encode(pil_to_bytes(texture_patch)).decode('utf-8')}})
            
        else:
            # Standard Edit
            task_prompt = f"""Edit instruction: {prompt}. Maintain photorealism.
{f'AVOID: {negative_prompt}' if negative_prompt else ''}"""
            parts.append({"text": task_prompt})
            parts.append({"inline_data": {"mime_type": "image/png", "data": base64.b64encode(pil_to_bytes(clean_source)).decode('utf-8')}})

    # è°ƒç”¨ Gemini API
    model = genai.GenerativeModel(MODEL_NAME)
    
    generated_images = []
    
    # æ¨¡æ‹Ÿ Batch (Python SDK ä¸æ”¯æŒä¸€æ¬¡è¿”å›å¤šå¼ ï¼Œéœ€è¦å¾ªç¯è°ƒç”¨)
    for _ in range(image_count):
        response = model.generate_content(
            parts,
            generation_config={"response_modalities": ["IMAGE"], "temperature": 0.4}
        )
        
        # è§£æç»“æœ
        if response.candidates and response.candidates[0].content.parts:
            part = response.candidates[0].content.parts[0]
            if part.inline_data:
                generated_images.append(part.inline_data.data) # Base64 bytes
            else:
                raise Exception("API è¿”å›äº†æ–‡æœ¬è€Œéå›¾ç‰‡ (å¯èƒ½æ˜¯æ‹’ç»å¤„ç†)")
        else:
            raise Exception("API æœªè¿”å›æœ‰æ•ˆå†…å®¹")
            
    return generated_images

# --- 4. UI ç•Œé¢ (å¤åˆ» App.tsx) ---

st.title("ğŸš€ Fashion AI Studio (Python Port)")
st.caption(f"Powered by {MODEL_NAME} | Logic Ported from geminiService.ts")

# åˆå§‹åŒ– Session State
if "generated_results" not in st.session_state:
    st.session_state["generated_results"] = []

# Mode Selector
mode_cols = st.columns(4)
modes = [
    ("general", "Global / Fusion"),
    ("inpainting", "Inpainting"),
    ("pose", "Pose Control"),
    ("upscale", "Upscale HD (TBD)")
]

# ç®€å•çš„æ¨¡å¼é€‰æ‹© UI
selected_mode = st.radio("é€‰æ‹©æ¨¡å¼ (Mode)", [m[1] for m in modes], horizontal=True)
current_mode_key = [m[0] for m in modes if m[1] == selected_mode][0]

col1, col2 = st.columns([5, 5])

with col1:
    st.markdown('<div class="step-card">', unsafe_allow_html=True)
    st.subheader("1. è¾“å…¥ (Inputs)")
    
    # ä¸»å›¾ä¸Šä¼ 
    source_file = st.file_uploader("ä¸Šä¼ ä¸»å›¾ (Source)", type=["jpg", "png", "webp"], key="src")
    source_img = None
    if source_file:
        source_img = Image.open(source_file).convert("RGB")
        st.image(source_img, caption="Source Image", width=200)

    # è¾…åŠ©å›¾ä¸Šä¼  (æ ¹æ®æ¨¡å¼)
    secondary_img = None
    if current_mode_key == 'inpainting':
        st.markdown("---")
        mask_file = st.file_uploader("ä¸Šä¼ è’™ç‰ˆ (Mask)", type=["jpg", "png", "webp"], key="mask")
        if mask_file:
            secondary_img = Image.open(mask_file).convert("L") # è½¬ç°åº¦
            st.image(secondary_img, caption="Mask", width=200)
            
        inpainting_region = st.radio("é‡ç»˜åŒºåŸŸ", ["inside (è’™ç‰ˆå†…éƒ¨)", "outside (è’™ç‰ˆå¤–éƒ¨/èƒŒæ™¯)"], index=0)
        
    elif current_mode_key == 'pose':
        st.markdown("---")
        pose_file = st.file_uploader("ä¸Šä¼ éª¨æ¶å›¾ (Pose)", type=["jpg", "png", "webp"], key="pose")
        if pose_file:
            secondary_img = Image.open(pose_file).convert("RGB")
            st.image(secondary_img, caption="Pose Skeleton", width=200)
            
    elif current_mode_key == 'general':
        st.markdown("---")
        ref_file = st.file_uploader("å‚è€ƒå›¾ (Reference - å¯é€‰)", type=["jpg", "png", "webp"], key="ref")
        if ref_file:
            secondary_img = Image.open(ref_file).convert("RGB")
            st.image(secondary_img, caption="Reference Image", width=200)
            
    st.markdown('</div>', unsafe_allow_html=True)

    # Prompt åŒºåŸŸ
    st.markdown('<div class="step-card">', unsafe_allow_html=True)
    st.subheader("2. æŒ‡ä»¤ (Instruction)")
    
    prompt_input = st.text_area(
        "æç¤ºè¯ (Prompt)", 
        value="Replace the background with a high-end studio setting. KEEP the metallic texture exactly as is.", 
        height=120
    )
    
    negative_input = st.text_input("è´Ÿå‘æç¤ºè¯ (Negative)", value="blur, bad anatomy, text, watermark")
    
    img_count = st.slider("ç”Ÿæˆæ•°é‡", 1, 4, 1)
    
    generate_btn = st.button("ğŸš€ å¼€å§‹ç”Ÿæˆ (Generate)", type="primary")
    st.markdown('</div>', unsafe_allow_html=True)

with col2:
    st.subheader("3. ç»“æœ (Result)")
    
    if generate_btn:
        if not source_img:
            st.warning("è¯·å…ˆä¸Šä¼ ä¸»å›¾ï¼")
        else:
            with st.spinner(f"æ­£åœ¨è°ƒç”¨ {MODEL_NAME} è¿›è¡Œç”Ÿæˆ... (çº¹ç†é”šå®šå·²å¯ç”¨)"):
                try:
                    # è½¬æ¢ inpainting_region å‚æ•°æ ¼å¼
                    region_param = 'inside' if 'inside' in (locals().get('inpainting_region', '')) else 'outside'
                    
                    results = generate_image(
                        original_img=source_img,
                        prompt=prompt_input,
                        mode=current_mode_key,
                        image_count=img_count,
                        secondary_img=secondary_img,
                        inpainting_region=region_param,
                        negative_prompt=negative_input
                    )
                    
                    st.session_state["generated_results"] = results
                    st.success(f"æˆåŠŸç”Ÿæˆ {len(results)} å¼ å›¾ç‰‡ï¼")
                    
                except Exception as e:
                    st.error(f"ç”Ÿæˆå¤±è´¥: {e}")
                    st.error("è¯·æ£€æŸ¥ API Key æƒé™æˆ–å°è¯•ç®€åŒ– Promptã€‚")

    # å±•ç¤ºç»“æœ
    if st.session_state["generated_results"]:
        for i, b64_data in enumerate(st.session_state["generated_results"]):
            try:
                img_data = base64.b64decode(b64_data)
                st.image(img_data, caption=f"Result {i+1}", use_column_width=True)
                
                # ä¸‹è½½æŒ‰é’®
                st.download_button(
                    f"ğŸ“¥ ä¸‹è½½ Result {i+1}",
                    data=img_data,
                    file_name=f"fashion_ai_result_{i+1}.png",
                    mime="image/png"
                )
            except Exception as e:
                st.error(f"ç»“æœ {i+1} æ˜¾ç¤ºå¤±è´¥: {e}")
