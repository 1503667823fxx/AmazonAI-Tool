import streamlit as st
import google.generativeai as genai
from PIL import Image
import io
import sys
import os
import time
from collections import deque 

# --- 0. åŸºç¡€è®¾ç½®ä¸æ ¸å¿ƒåº“å¼•å…¥ ---
sys.path.append(os.path.abspath('.'))

# 1. å°è¯•å¯¼å…¥ auth (å¦‚æœä¸å­˜åœ¨åˆ™è·³è¿‡ï¼Œä¸å½±å“æ ¸å¿ƒåŠŸèƒ½)
try:
    import auth
    HAS_AUTH = True
except ImportError:
    HAS_AUTH = False

# 2. å°è¯•å¯¼å…¥æ ¸å¿ƒå·¥å…· (æ ¸å¿ƒä¾èµ–ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨å¤‡ç”¨)
try:
    from core_utils import AITranslator, process_image_for_download, create_preview_thumbnail, HistoryManager, show_preview_modal
except ImportError:
    # å¤‡ç”¨ç±»å®šä¹‰ (é˜²æ­¢æŠ¥é”™)
    class AITranslator:
        def to_english(self, t): return t
        def to_chinese(self, t): return t
    class HistoryManager:
        def add(self, a, b, c): pass
        def render_sidebar(self): pass
    
    # ä¿®å¤ï¼šå¤‡ç”¨å‡½æ•°å¿…é¡»æ¥æ”¶ format å‚æ•°
    def process_image_for_download(b, format="PNG"): return b, "image/png"
    
    # ä¿®å¤ï¼šå¤‡ç”¨å‡½æ•°å¿…é¡»æ¥æ”¶ max_width å‚æ•° (è¿™æ˜¯ä¹‹å‰æŠ¥é”™çš„æ ¹æº)
    def create_preview_thumbnail(b, max_width=800): return b
    
    def show_preview_modal(b, c): pass

st.set_page_config(page_title="Fashion AI Core", page_icon="ğŸ§¬", layout="wide")

# é—¨ç¦æ£€æŸ¥ (ä»…åœ¨ auth å­˜åœ¨æ—¶å¯ç”¨)
if HAS_AUTH and 'auth' in sys.modules:
    if not auth.check_password():
        st.stop()

# API Key æ£€æŸ¥
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° GOOGLE_API_KEY")
    st.stop()

# --- åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶ ---
if "translator" not in st.session_state:
    st.session_state.translator = AITranslator()
if "history_manager" not in st.session_state:
    st.session_state.history_manager = HistoryManager()

# --- æ ·å¼ä¼˜åŒ– ---
st.markdown("""
<style>
    .step-header {
        background: linear-gradient(90deg, #e3f2fd 0%, #ffffff 100%);
        padding: 12px 20px;
        border-radius: 8px;
        border-left: 6px solid #2196F3;
        margin-top: 25px;
        margin-bottom: 15px;
        font-weight: 600;
        color: #0D47A1;
        font-size: 1.1rem;
    }
    .stButton button {
        border-radius: 8px;
        height: 3em; 
        font-weight: bold;
    }
    .stTextArea { margin-bottom: 0px; }
    .stAlert { padding: 10px; }
</style>
""", unsafe_allow_html=True)

# --- å¸¸é‡ ---
ANALYSIS_MODELS = ["models/gemini-flash-latest", "models/gemini-2.5-pro", "models/gemini-3-pro-preview"]
GOOGLE_IMG_MODELS = ["models/gemini-2.5-flash-image", "models/gemini-3-pro-image-preview"]
RATIO_MAP = {
    "1:1 (æ­£æ–¹å½¢ç”µå•†å›¾)": ", crop and center composition to 1:1 square aspect ratio",
    "4:3 (å¸¸è§„æ¨ªå‘)": ", adjust composition to 4:3 landscape aspect ratio",
    "21:9 (ç”µå½±æ„Ÿè¶…å®½)": ", cinematic 21:9 ultrawide aspect ratio"
}

# --- çŠ¶æ€ç®¡ç† ---
# Tab 1: æ ‡å‡†å·¥ä½œæµ
if "std_prompt_data" not in st.session_state: st.session_state["std_prompt_data"] = [] 
if "std_images" not in st.session_state: st.session_state["std_images"] = []

# Tab 2: æ”¹æ¬¾
if "var_prompt_en" not in st.session_state: st.session_state["var_prompt_en"] = ""
if "var_prompt_zh" not in st.session_state: st.session_state["var_prompt_zh"] = ""
if "batch_results" not in st.session_state: st.session_state["batch_results"] = []

# Tab 3: æ¢èƒŒæ™¯
if "bg_prompt_en" not in st.session_state: st.session_state["bg_prompt_en"] = ""
if "bg_prompt_zh" not in st.session_state: st.session_state["bg_prompt_zh"] = ""
if "bg_results" not in st.session_state: st.session_state["bg_results"] = []

# --- è¾…åŠ©å‡½æ•° ---
def generate_image_call(model_name, prompt, image_input, ratio_suffix):
    # å‡€åŒ– Prompt
    clean_prompt = prompt.replace("16:9", "").replace("4:3", "").replace("1:1", "").replace("Aspect Ratio", "")
    final_prompt = clean_prompt + ratio_suffix + ", high quality, 8k resolution, photorealistic, commercial lighting"
    gen_model = genai.GenerativeModel(model_name)
    try:
        response = gen_model.generate_content([final_prompt, image_input], stream=True)
        for chunk in response:
            if hasattr(chunk, "parts"):
                for part in chunk.parts:
                    if part.inline_data:
                        return part.inline_data.data
    except Exception as e:
        print(f"Error: {e}")
        return None
    return None

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("ğŸ—‚ï¸ å·¥ä½œåŒº")
    download_format = st.radio("ğŸ“¥ ä¸‹è½½æ ¼å¼", ["PNG", "JPEG"], horizontal=True)
    # æ¸²æŸ“å†å²è®°å½•
    st.session_state.history_manager.render_sidebar()

# ==========================================
# ğŸš€ ä¸»ç•Œé¢
# ==========================================
st.title("ğŸ§¬ Fashion AI Core V5.6")
tab_workflow, tab_variants, tab_background = st.tabs(["âœ¨ æ ‡å‡†ç²¾ä¿® (Workstation)", "âš¡ å˜ä½“æ”¹æ¬¾", "ğŸï¸ åœºæ™¯ç½®æ¢"])

# ==========================================
# TAB 1: æ ‡å‡†å·¥ä½œæµ (æ”¯æŒå¤šå›¾ä¸Šä¼  + å¯é€‰æ‹†åˆ† + æƒé‡æ§åˆ¶)
# ==========================================
with tab_workflow:
    col_main, col_preview = st.columns([1.5, 1], gap="large")

    with col_main:
        st.markdown('<div class="step-header">Step 1: éœ€æ±‚åˆ†æ</div>', unsafe_allow_html=True)
        
        c1, c2 = st.columns([1, 1])
        with c1: analysis_model = st.selectbox("1. è¯»å›¾æ¨¡å‹", ANALYSIS_MODELS, index=0)
        with c2: 
            uploaded_files = st.file_uploader("2. ä¸Šä¼ å‚è€ƒå›¾ (æ”¯æŒå¤šé€‰)", type=["jpg", "png", "webp"], key="std_upload", accept_multiple_files=True)

        active_file = None
        if uploaded_files:
            if len(uploaded_files) > 1:
                file_names = [f.name for f in uploaded_files]
                selected_name = st.selectbox("ğŸ‘‰ é€‰æ‹©å½“å‰è¦å¤„ç†çš„å›¾ç‰‡:", file_names)
                for f in uploaded_files:
                    if f.name == selected_name:
                        active_file = f
                        break
            else:
                active_file = uploaded_files[0]
        
        task_type = st.selectbox("3. ä»»åŠ¡ç±»å‹", ["åœºæ™¯å›¾ (Lifestyle)", "å±•ç¤ºå›¾ (Creative)", "äº§å“å›¾ (Product Only)"])
        user_idea = st.text_area("4. ä½ çš„åˆ›æ„", height=80, placeholder="ä¾‹å¦‚ï¼šæ”¹ä¸ºæç®€ä¸»ä¹‰é£æ ¼ï¼Œç™½è‰²èƒŒæ™¯...")

        # åˆ›æ„æƒé‡æ»‘å—
        user_weight = st.slider(
            "5. åˆ›æ„æƒé‡ (User Influence)", 
            0.0, 1.0, 0.6, step=0.1, 
            help="0.0 = å®Œå…¨å¬AIçš„(å¿ å®åŸå›¾); 1.0 = å®Œå…¨å¬ä½ çš„(å¿ å®æ–‡å­—); 0.6 = å¹³è¡¡æ¨¡å¼"
        )

        # æ‹†åˆ†ä»»åŠ¡å¼€å…³
        enable_split = st.checkbox("ğŸ§© å¯ç”¨æ™ºèƒ½ä»»åŠ¡æ‹†åˆ† (å¤šä»»åŠ¡æ¨¡å¼)", value=False, help="å‹¾é€‰åï¼ŒAI ä¼šå°è¯•å°†å¤æ‚éœ€æ±‚(å¦‚'ä¸€å¼ ä¸Šè¡£ï¼Œä¸€å¼ è£¤å­')æ‹†è§£ä¸ºå¤šä¸ªç‹¬ç«‹çš„ç”Ÿå›¾ä»»åŠ¡ã€‚")

        if st.button("ğŸ§  ç”Ÿæˆ Prompt", type="primary"):
            if not active_file: st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æˆ–é€‰æ‹©å›¾ç‰‡")
            else:
                with st.spinner(f"AI æ­£åœ¨åˆ†æ (æƒé‡: {user_weight})..."):
                    try:
                        active_file.seek(0)
                        img_obj = Image.open(active_file)
                        model = genai.GenerativeModel(analysis_model)
                        
                        # æ³¨å…¥é«˜è´¨é‡æ‘„å½±æŒ‡ä»¤
                        special_instruction = ""
                        if "Product Only" in task_type:
                            special_instruction = """
                            SPECIAL INSTRUCTION FOR PRODUCT PHOTOGRAPHY:
                            1. **Layout**: If user implies 'flat lay' or 'break down', use "Knolling photography", "Neatly arranged".
                            2. **Realism**: Use "Contact shadows", "Ambient occlusion" to avoid floating look.
                            3. **Texture**: Emphasize "fabric texture", "material details".
                            """
                        
                        # æ ¸å¿ƒæƒé‡é€»è¾‘æ³¨å…¥
                        weight_instruction = f"""
                        WEIGHT CONTROL INSTRUCTION (Important):
                        The user has set an influence weight of {user_weight} (Range 0.0 to 1.0).
                        - If weight > 0.7: Prioritize the User's Idea ('{user_idea}') over the visual analysis of the image. Even if it conflicts with the image, follow the text.
                        - If weight < 0.3: Prioritize the Visual Analysis of the image. Use the User's Idea only as a subtle suggestion.
                        - If weight is 0.4-0.6: Balance both equally.
                        """

                        if enable_split:
                            prompt_req = f"""
                            Role: Art Director. 
                            Task: Create detailed prompts based on User Idea and Image. Type: {task_type}.
                            {weight_instruction}
                            {special_instruction}
                            IMPORTANT LOGIC: Split distinct outputs into separate prompts using "|||".
                            STRICT OUTPUT FORMAT: Separate prompts with "|||". NO Markdown.
                            User Idea: {user_idea}
                            Output: English Prompts Only.
                            """
                        else:
                            prompt_req = f"""
                            Role: Art Director. 
                            Task: Create ONE single, high-quality prompt based on User Idea and Image. Type: {task_type}.
                            {weight_instruction}
                            {special_instruction}
                            STRICT OUTPUT FORMAT: Provide ONE unified prompt. NO "|||". NO Markdown.
                            User Idea: {user_idea}
                            Output: English Prompt Only.
                            """

                        response = model.generate_content([prompt_req, img_obj])
                        raw_text = response.text.strip()
                        
                        prompt_list = raw_text.split("|||")
                        
                        st.session_state["std_prompt_data"] = []
                        for p in prompt_list:
                            p_en = p.strip()
                            if p_en:
                                p_zh = st.session_state.translator.to_chinese(p_en)
                                st.session_state["std_prompt_data"].append({"en": p_en, "zh": p_zh})
                        st.rerun()
                    except Exception as e: st.error(f"åˆ†æå¤±è´¥: {e}")

        # Step 2: ä»»åŠ¡æ¸²æŸ“åŒº
        if st.session_state["std_prompt_data"]:
            st.markdown('<div class="step-header">Step 2: ä»»åŠ¡æ‰§è¡Œ</div>', unsafe_allow_html=True)
            
            for i, p_data in enumerate(st.session_state["std_prompt_data"]):
                expander_label = f"ğŸ“ ä»»åŠ¡ {i+1}" if len(st.session_state["std_prompt_data"]) > 1 else "ğŸ“ ç”ŸæˆæŒ‡ä»¤å¾®è°ƒ"
                
                with st.expander(expander_label, expanded=True):
                    col_zh, col_en = st.columns(2)
                    with col_zh:
                        key_zh = f"std_zh_{i}"
                        if key_zh not in st.session_state: st.session_state[key_zh] = p_data["zh"]
                        # TAB 1 çš„åŒæ­¥é€»è¾‘ï¼šæ›´æ–°åˆ—è¡¨ä¸­çš„æ•°æ®
                        def update_en(idx=i):
                            new_zh = st.session_state[f"std_zh_{idx}"]
                            new_en = st.session_state.translator.to_english(new_zh)
                            st.session_state["std_prompt_data"][idx]["zh"] = new_zh
                            st.session_state["std_prompt_data"][idx]["en"] = new_en
                        st.text_area("ä¸­æ–‡æŒ‡ä»¤ (å¯ç¼–è¾‘)", key=key_zh, height=100, on_change=update_en)
                    with col_en:
                        st.text_area("English Prompt (åªè¯»)", value=st.session_state["std_prompt_data"][i]["en"], height=100, disabled=True, key=f"std_en_view_{i}")

            cg1, cg2, cg3 = st.columns(3)
            with cg1: google_model = st.selectbox("æ¨¡å‹", GOOGLE_IMG_MODELS)
            with cg2: selected_ratio_key = st.selectbox("æ¯”ä¾‹", list(RATIO_MAP.keys()))
            with cg3: num_images = st.number_input("å•ä»»åŠ¡ç”Ÿæˆæ•°é‡", 1, 4, 1)

            if "flash" in google_model and "1:1" not in selected_ratio_key:
                st.warning("âš ï¸ è­¦å‘Šï¼šGemini 2.5 Flash å¼ºåˆ¶ 1:1 è¾“å‡ºã€‚")

            if st.button("ğŸ¨ å¼€å§‹ç”Ÿæˆ", type="primary"):
                st.session_state["std_images"] = []
                total_tasks = len(st.session_state["std_prompt_data"]) * num_images
                current_progress = 0
                bar = st.progress(0)
                
                if active_file:
                    active_file.seek(0)
                    img_pil = Image.open(active_file)
                    for task_idx, task_data in enumerate(st.session_state["std_prompt_data"]):
                        prompt_en = task_data["en"]
                        prompt_zh = task_data["zh"]
                        for n in range(num_images):
                            with st.spinner(f"æ‰§è¡Œä»»åŠ¡ {task_idx+1} (ç¬¬ {n+1} å¼ )..."):
                                active_file.seek(0)
                                # å†æ¬¡ç¡®è®¤è¯»å–ï¼Œé˜²æ­¢æŒ‡é’ˆé—®é¢˜
                                img_pil = Image.open(active_file)
                                img_data = generate_image_call(google_model, prompt_en, img_pil, RATIO_MAP[selected_ratio_key])
                                if img_data:
                                    st.session_state["std_images"].append(img_data)
                                    st.session_state.history_manager.add(img_data, f"Task {task_idx+1}", prompt_zh)
                                current_progress += 1
                                bar.progress(current_progress / total_tasks)
                                time.sleep(1)
                    st.success("ğŸ‰ æ‰§è¡Œå®Œæ¯•ï¼")

    # å³ä¾§é¢„è§ˆ (TAB 1)
    with col_preview:
        st.subheader("ğŸ–¼ï¸ ç»“æœé¢„è§ˆ")
        if active_file:
            with st.expander("ğŸ” å½“å‰å‚è€ƒå›¾", expanded=True):
                active_file.seek(0)
                st.image(Image.open(active_file), use_container_width=True)

        if st.session_state["std_images"]:
            st.divider()
            for idx, img_bytes in enumerate(st.session_state["std_images"]):
                thumb = create_preview_thumbnail(img_bytes, max_width=400)
                st.image(thumb, caption=f"Result {idx+1}", width=350)
                
                c_btn1, c_btn2 = st.columns([1.5, 1])
                with c_btn1:
                    final_bytes, mime = process_image_for_download(img_bytes, format=download_format)
                    st.download_button(f"ğŸ“¥ ä¸‹è½½", data=final_bytes, file_name=f"std_{idx}.{download_format.lower()}", mime=mime, use_container_width=True)
                with c_btn2:
                    if st.button(f"ğŸ” æ”¾å¤§", key=f"zoom_std_{idx}", use_container_width=True):
                        show_preview_modal(img_bytes, f"Result {idx+1}")

# ==========================================
# TAB 2: âš¡ å˜ä½“æ”¹æ¬¾ (Restyling) - ä¼˜åŒ–ç‰ˆ
# ==========================================
with tab_variants:
    st.markdown("### âš¡ æœè£…æ”¹æ¬¾å·¥å‚")
    
    cv_left, cv_right = st.columns([1.5, 1], gap="large")

    # TAB 2 çš„åŒæ­¥é€»è¾‘ï¼šæ›´æ–°å…¨å±€å˜é‡ var_prompt_en
    def update_var_en():
        val = st.session_state.var_prompt_zh
        if val:
            st.session_state.var_prompt_en = st.session_state.translator.to_english(val)
    
    with cv_left:
        st.markdown("#### Step 1: AI è¯»å–äº§å“ç‰¹å¾")
        var_file = st.file_uploader("ä¸Šä¼ åŸç‰ˆå›¾ç‰‡", type=["jpg", "png"], key="var_upload")
        var_ana_model = st.selectbox("åˆ†ææ¨¡å‹", ANALYSIS_MODELS, index=0, key="var_ana_model")
        
        if st.button("ğŸ‘ï¸ AI è¯»å›¾", key="btn_var_ana"):
            if not var_file: st.warning("è¯·å…ˆä¸Šä¼ ")
            else:
                with st.spinner("æå–ä¸­..."):
                    try:
                        var_file.seek(0)
                        v_img = Image.open(var_file)
                        model = genai.GenerativeModel(var_ana_model)
                        prompt = "Describe the main fashion product details: Silhouette, Fabric, Color, Pattern. Output pure text."
                        resp = model.generate_content([prompt, v_img])
                        
                        en_text = resp.text.strip()
                        st.session_state["var_prompt_en"] = en_text
                        st.session_state["var_prompt_zh"] = st.session_state.translator.to_chinese(en_text)
                        st.success("æˆåŠŸ")
                    except Exception as e: st.error(f"å¤±è´¥: {e}")

        # Step 2: æ”¹æ¬¾è®¾ç½®
        st.markdown("#### Step 2: æ”¹æ¬¾è®¾ç½®")
        
        vp_col1, vp_col2 = st.columns(2)
        with vp_col1:
            # ç»‘å®š on_change äº‹ä»¶åˆ°åŒæ­¥å‡½æ•°
            st.text_area("ğŸ‡¨ğŸ‡³ ç‰¹å¾æè¿° (ä¸­æ–‡ - å¯ç¼–è¾‘)", key="var_prompt_zh", height=100, on_change=update_var_en)
        with vp_col2:
            st.text_area("ğŸ‡ºğŸ‡¸ Feature Desc (English - Auto)", key="var_prompt_en", height=100, disabled=True)

        CHANGE_LEVELS = {
            "ğŸ¨ å¾®è°ƒ (çº¹ç†/é¢æ–™)": "Keep silhouette exactly same. Only modify fabric.",
            "âœ‚ï¸ ä¸­æ”¹ (é¢†å£/è¢–å£)": "Keep fit. Modify details like collar/sleeves.",
            "ğŸª„ å¤§æ”¹ (ç‰ˆå‹é‡æ„)": "Redesign silhouette based on vibe."
        }
        change_level = st.selectbox("æ”¹æ¬¾å¹…åº¦", list(CHANGE_LEVELS.keys()))
        user_mod = st.text_area("æ”¹æ¬¾æŒ‡ä»¤", height=60)
        
        batch_count = st.slider("æ•°é‡", 1, 20, 4, key="var_batch")
        var_model = st.selectbox("æ¨¡å‹", GOOGLE_IMG_MODELS, key="var_gen_model")
        start_batch = st.button("ğŸš€ å¯åŠ¨æ‰¹é‡æ”¹æ¬¾", type="primary")

    with cv_right:
        st.subheader("ğŸ–¼ï¸ ç»“æœé¢„è§ˆ")
        
        if var_file:
            with st.expander("ğŸ” åŸå›¾é¢„è§ˆ", expanded=True):
                var_file.seek(0)
                st.image(Image.open(var_file), use_container_width=True)

        if start_batch and var_file and st.session_state["var_prompt_en"]:
            st.session_state["batch_results"] = []
            st.divider()
            grid = st.columns(2)
            sys_instruct = CHANGE_LEVELS[change_level]
            my_bar = st.progress(0)
            
            for i in range(batch_count):
                try:
                    var_file.seek(0)
                    v_img = Image.open(var_file)
                    # AI è¯»å–çš„æ˜¯ session_state['var_prompt_en']ï¼Œå®ƒå·²ç»è¢«åŒæ­¥å‡½æ•°æ›´æ–°äº†
                    prompt = f"Task: Restyling. Base: {st.session_state['var_prompt_en']}. Constraint: {sys_instruct}. Mod Request: {user_mod}. Var ID: {i}"
                    img_data = generate_image_call(var_model, prompt, v_img, "")
                    if img_data:
                        st.session_state["batch_results"].append(img_data)
                        st.session_state.history_manager.add(img_data, f"Restyle {i+1}", user_mod)
                        
                        with grid[i%2]:
                            thumb = create_preview_thumbnail(img_data, max_width=300)
                            st.image(thumb, use_container_width=True)
                            if st.button("ğŸ”", key=f"zoom_var_{i}"):
                                show_preview_modal(img_data, f"Var {i+1}")
                except Exception as e: print(f"VarGen Error: {e}")
                my_bar.progress((i+1)/batch_count)
                time.sleep(1)
        
        if st.session_state["batch_results"]:
            st.divider()
            for idx, img_bytes in enumerate(st.session_state["batch_results"]):
                final_bytes, mime = process_image_for_download(img_bytes, format=download_format)
                st.download_button(f"ğŸ“¥ ä¸‹è½½ {idx+1}", final_bytes, file_name=f"var_{idx}.{download_format.lower()}", mime=mime)

# ==========================================
# TAB 3: ğŸï¸ åœºæ™¯ç½®æ¢ (Scene Swap) - ä¼˜åŒ–ç‰ˆ
# ==========================================
with tab_background:
    st.markdown("### ğŸï¸ åœºæ™¯æ‰¹é‡ç½®æ¢")
    
    cb_left, cb_right = st.columns([1.5, 1], gap="large")

    # TAB 3 çš„åŒæ­¥é€»è¾‘ï¼šæ›´æ–°å…¨å±€å˜é‡ bg_prompt_en
    def update_bg_en():
        val = st.session_state.bg_prompt_zh
        if val:
            st.session_state.bg_prompt_en = st.session_state.translator.to_english(val)

    with cb_left:
        st.markdown("#### Step 1: AI é”å®šäº§å“")
        bg_file = st.file_uploader("ä¸Šä¼ äº§å“å›¾", type=["jpg", "png"], key="bg_upload")
        bg_ana_model = st.selectbox("åˆ†ææ¨¡å‹", ANALYSIS_MODELS, index=0, key="bg_ana_model")
        
        if st.button("ğŸ”’ é”å®šäº§å“ç‰¹å¾", key="btn_bg_ana"):
            if not bg_file: st.warning("è¯·å…ˆä¸Šä¼ ")
            else:
                with st.spinner("é”å®šä¸­..."):
                    try:
                        bg_file.seek(0)
                        v_img = Image.open(bg_file)
                        model = genai.GenerativeModel(bg_ana_model)
                        prompt = "Describe FOREGROUND PRODUCT ONLY in detail. Ignore background. Output pure text."
                        resp = model.generate_content([prompt, v_img])
                        
                        en_text = resp.text.strip()
                        st.session_state["bg_prompt_en"] = en_text
                        st.session_state["bg_prompt_zh"] = st.session_state.translator.to_chinese(en_text)
                        st.success("é”å®šæˆåŠŸ")
                    except Exception as e: st.error(f"å¤±è´¥: {e}")

        # Step 2: æ¢èƒŒæ™¯è®¾ç½®
        st.markdown("#### Step 2: æ¢èƒŒæ™¯è®¾ç½®")
        bp_col1, bp_col2 = st.columns(2)
        with bp_col1:
            # ç»‘å®š on_change äº‹ä»¶åˆ°åŒæ­¥å‡½æ•°
            st.text_area("ğŸ‡¨ğŸ‡³ äº§å“ç‰¹å¾ (ä¸­æ–‡ - å¯ç¼–è¾‘)", key="bg_prompt_zh", height=100, on_change=update_bg_en)
        with bp_col2:
            st.text_area("ğŸ‡ºğŸ‡¸ Product Features (English - Auto)", key="bg_prompt_en", height=100, disabled=True)
        
        bg_desc = st.text_area("æ–°èƒŒæ™¯æè¿°", height=60, placeholder="ä¾‹å¦‚ï¼šæ”¾åœ¨æœ¨è´¨çº¹ç†çš„æ¡Œé¢ä¸Š...")
        bg_count = st.slider("æ•°é‡", 1, 20, 4, key="bg_count")
        bg_model = st.selectbox("æ¨¡å‹", GOOGLE_IMG_MODELS, index=1, key="bg_gen_model")
        start_bg = st.button("ğŸš€ å¯åŠ¨æ¢èƒŒæ™¯", type="primary")

    with cb_right:
        st.subheader("ğŸ–¼ï¸ ç»“æœé¢„è§ˆ")

        if bg_file:
            with st.expander("ğŸ” åŸå›¾é¢„è§ˆ", expanded=True):
                bg_file.seek(0)
                st.image(Image.open(bg_file), use_container_width=True)

        if start_bg and bg_file and st.session_state["bg_prompt_en"]:
            st.session_state["bg_results"] = []
            st.divider()
            bg_grid = st.columns(2)
            bg_bar = st.progress(0)
            
            for i in range(bg_count):
                try:
                    bg_file.seek(0)
                    v_img = Image.open(bg_file)
                    # AI è¯»å–çš„æ˜¯ session_state['bg_prompt_en']
                    prompt = f"Product BG Swap. Product: {st.session_state['bg_prompt_en']}. New BG: {bg_desc}. Constraint: KEEP PRODUCT SAME. Var ID: {i}"
                    img_data = generate_image_call(bg_model, prompt, v_img, "")
                    if img_data:
                        st.session_state["bg_results"].append(img_data)
                        st.session_state.history_manager.add(img_data, f"BG Swap {i+1}", bg_desc)
                        
                        with bg_grid[i%2]:
                            thumb = create_preview_thumbnail(img_data, max_width=300)
                            st.image(thumb, use_container_width=True)
                            if st.button("ğŸ”", key=f"zoom_bg_{i}"):
                                show_preview_modal(img_data, f"Scene {i+1}")
                except Exception as e: print(f"BGGen Error: {e}")
                bg_bar.progress((i+1)/bg_count)
                time.sleep(1)
        
        if st.session_state["bg_results"]:
            st.divider()
            for idx, img_bytes in enumerate(st.session_state["bg_results"]):
                final_bytes, mime = process_image_for_download(img_bytes, format=download_format)
                st.download_button(f"ğŸ“¥ ä¸‹è½½ {idx+1}", final_bytes, file_name=f"scene_{idx}.{download_format.lower()}", mime=mime)
