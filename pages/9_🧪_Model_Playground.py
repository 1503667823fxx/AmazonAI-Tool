import streamlit as st
import google.generativeai as genai
from PIL import Image
import io
import sys
import os
import base64

# --- 0. å¼•å…¥é—¨ç¦ç³»ç»Ÿ ---
sys.path.append(os.path.abspath('.'))
try:
    import auth
except ImportError:
    pass 

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="æ¨¡å‹è¯•é©¾åœº", page_icon="ğŸ§ª", layout="wide")

# å®‰å…¨æ£€æŸ¥
if 'auth' in sys.modules:
    if not auth.check_password():
        st.stop()

st.title("ğŸ§ª Gemini æ¨¡å‹è¯•é©¾åœº (Model Playground)")
st.caption("è¿™é‡Œæ˜¯çº¯å‡€çš„æµ‹è¯•ç¯å¢ƒï¼Œç”¨äºæ’æŸ¥ API æƒé™å’Œæ¨¡å‹èƒ½åŠ›ã€‚")

# --- 2. éªŒè¯ API Key ---
if "GOOGLE_API_KEY" not in st.secrets:
    st.error("âŒ æœªæ‰¾åˆ° Google API Keyï¼Œè¯·åœ¨ secrets.toml ä¸­é…ç½®ã€‚")
    st.stop()

genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])

# --- 3. ä¾§è¾¹æ ï¼šæ¨¡å‹æ¢æµ‹å™¨ ---
with st.sidebar:
    st.header("ğŸ“¡ æ¨¡å‹æ¢æµ‹é›·è¾¾")
    
    if st.button("ğŸ”„ æ‰«æå¯ç”¨æ¨¡å‹"):
        try:
            with st.spinner("æ­£åœ¨è¿æ¥ Google æœåŠ¡å™¨..."):
                all_models = []
                # åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
                for m in genai.list_models():
                    all_models.append(m)
                
                st.session_state["all_models_list"] = all_models
                st.success(f"æ‰«ææˆåŠŸï¼å…±å‘ç° {len(all_models)} ä¸ªæ¨¡å‹ã€‚")
        except Exception as e:
            st.error(f"æ‰«æå¤±è´¥: {e}")

    # ç­›é€‰é€»è¾‘
    all_models = st.session_state.get("all_models_list", [])
    
    # æå–æ”¯æŒ generateContent çš„æ¨¡å‹ (ç”¨äºå¯¹è¯/è¯†å›¾)
    chat_models = [m.name for m in all_models if 'generateContent' in m.supported_generation_methods]
    # æå–å¯èƒ½æ”¯æŒç”Ÿå›¾çš„æ¨¡å‹ (é€šè¿‡åå­—çŒœæµ‹ï¼Œé€šå¸¸åŒ…å« image)
    image_models = [m.name for m in all_models if 'image' in m.name.lower() or 'vision' in m.name.lower()]
    
    st.markdown("---")
    st.markdown(f"**ğŸ” å‘ç° {len(chat_models)} ä¸ªç”Ÿæˆæ¨¡å‹**")
    
    # é€‰æ‹©å½“å‰æµ‹è¯•çš„æ¨¡å‹
    selected_model_name = st.selectbox(
        "é€‰æ‹©è¦æµ‹è¯•çš„æ¨¡å‹:", 
        options=chat_models if chat_models else ["models/gemini-1.5-flash"], # é»˜è®¤å€¼
        index=0 if chat_models else 0
    )

# --- 4. ä¸»ç•Œé¢ï¼šå¤šåŠŸèƒ½æµ‹è¯•å° ---
tab1, tab2, tab3 = st.tabs(["ğŸ’¬ çº¯æ–‡æœ¬å¯¹è¯", "ğŸ‘ï¸ å¤šæ¨¡æ€è¯†å›¾", "ğŸ¨ å›¾åƒç”Ÿæˆæµ‹è¯•"])

# === Tab 1: çº¯æ–‡æœ¬å¯¹è¯ ===
with tab1:
    st.subheader(f"æ­£åœ¨æµ‹è¯•: `{selected_model_name}`")
    user_input = st.text_input("è¾“å…¥æµ‹è¯•æ–‡æœ¬", "Hello, who are you?")
    
    if st.button("å‘é€ (Text Chat)", key="btn_chat"):
        try:
            model = genai.GenerativeModel(selected_model_name)
            response = model.generate_content(user_input)
            st.success("âœ… å“åº”æˆåŠŸ:")
            st.write(response.text)
        except Exception as e:
            st.error(f"âŒ å¤±è´¥: {e}")

# === Tab 2: å¤šæ¨¡æ€è¯†å›¾ ===
with tab2:
    st.subheader(f"æ­£åœ¨æµ‹è¯•: `{selected_model_name}`")
    st.info("æµ‹è¯•è¯¥æ¨¡å‹æ˜¯å¦å…·å¤‡ Vision (è§†è§‰) èƒ½åŠ›ã€‚")
    
    uploaded_img = st.file_uploader("ä¸Šä¼ æµ‹è¯•å›¾ç‰‡", type=["jpg", "png", "webp"], key="vision_up")
    vision_prompt = st.text_input("è¾“å…¥æŒ‡ä»¤", "Describe this image in detail.")
    
    if uploaded_img and st.button("å‘é€ (Vision)", key="btn_vision"):
        try:
            image = Image.open(uploaded_img)
            st.image(image, width=200)
            
            model = genai.GenerativeModel(selected_model_name)
            response = model.generate_content([vision_prompt, image])
            st.success("âœ… å“åº”æˆåŠŸ:")
            st.write(response.text)
        except Exception as e:
            st.error(f"âŒ å¤±è´¥: {e}")
            st.warning("æç¤ºï¼šå¦‚æœæŠ¥é”™ï¼Œè¯´æ˜è¯¥æ¨¡å‹å¯èƒ½ä¸æ”¯æŒå¤šæ¨¡æ€è¾“å…¥ï¼ˆåªèƒ½è¯»å­—ï¼Œä¸èƒ½çœ‹å›¾ï¼‰ã€‚")

# === Tab 3: å›¾åƒç”Ÿæˆæµ‹è¯• (å…³é”®æˆ˜åœº) ===
with tab3:
    st.subheader(f"æ­£åœ¨æµ‹è¯•: `{selected_model_name}`")
    st.warning("âš ï¸ æ³¨æ„ï¼šåªæœ‰ç‰¹å®šæ¨¡å‹ï¼ˆå¦‚ imagen æˆ– gemini-imageï¼‰æ‰æ”¯æŒç”Ÿå›¾ã€‚ç”¨æ™®é€šæ¨¡å‹æµ‹è¯•å¿…ç„¶æŠ¥é”™ã€‚")
    
    col_gen1, col_gen2 = st.columns(2)
    
    with col_gen1:
        st.markdown("#### A. æ–‡ç”Ÿå›¾ (Text to Image)")
        t2i_prompt = st.text_input("ç”Ÿå›¾æç¤ºè¯", "A cute robot holding a Streamlit logo, 3d render")
        
        if st.button("ğŸ¨ æµ‹è¯•æ–‡ç”Ÿå›¾", key="btn_t2i"):
            try:
                model = genai.GenerativeModel(selected_model_name)
                # å¼ºåˆ¶è¦æ±‚è¿”å›å›¾ç‰‡
                response = model.generate_content(
                    t2i_prompt,
                    generation_config={"response_modalities": ["IMAGE"]}
                )
                
                # è§£æ
                try:
                    if not response.parts:
                        st.error("æœªè¿”å› Partsã€‚")
                    else:
                        part = response.parts[0]
                        if part.text:
                            st.warning(f"AI è¿”å›äº†æ–‡æœ¬è€Œä¸æ˜¯å›¾ç‰‡: {part.text}")
                        elif part.inline_data:
                            img_data = base64.b64decode(part.inline_data.data)
                            st.image(img_data, caption="ç”Ÿæˆç»“æœ")
                            st.success("ğŸ‰ æˆåŠŸï¼è¯¥æ¨¡å‹æ”¯æŒæ–‡ç”Ÿå›¾ï¼")
                except Exception as parse_err:
                    st.error(f"è§£æå¤±è´¥: {parse_err}")
                    
            except Exception as e:
                st.error(f"âŒ è¯·æ±‚å¤±è´¥: {e}")

    with col_gen2:
        st.markdown("#### B. å›¾ç”Ÿå›¾ (Image to Image)")
        ref_img_gen = st.file_uploader("ä¸Šä¼ å‚è€ƒå›¾", type=["jpg", "png"], key="gen_up")
        i2i_prompt = st.text_input("ç¼–è¾‘æŒ‡ä»¤", "Change the background to a beach")
        
        if ref_img_gen and st.button("ğŸ¨ æµ‹è¯•å›¾ç”Ÿå›¾", key="btn_i2i"):
            try:
                img_obj = Image.open(ref_img_gen)
                st.image(img_obj, width=150, caption="è¾“å…¥å›¾")
                
                model = genai.GenerativeModel(selected_model_name)
                
                # å°è¯•å‘é€ [prompt, image]
                response = model.generate_content(
                    [i2i_prompt, img_obj],
                    generation_config={"response_modalities": ["IMAGE"]}
                )
                
                # è§£æ
                try:
                    if not response.parts:
                        st.error("æœªè¿”å› Partsã€‚")
                    else:
                        part = response.parts[0]
                        if part.text:
                            st.warning(f"AI è¿”å›äº†æ–‡æœ¬: {part.text}")
                        elif part.inline_data:
                            img_data = base64.b64decode(part.inline_data.data)
                            st.image(img_data, caption="ç”Ÿæˆç»“æœ")
                            st.success("ğŸ‰ æˆåŠŸï¼è¯¥æ¨¡å‹æ”¯æŒå›¾ç”Ÿå›¾ï¼")
                except Exception as parse_err:
                    st.error(f"è§£æå¤±è´¥: {parse_err}")
                    
            except Exception as e:
                st.error(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
                st.info("å¦‚æœæŠ¥é”™ '400 Bad Request' æˆ– 'multimodal input not supported'ï¼Œè¯´æ˜è¯¥æ¨¡å‹ä¸æ”¯æŒæ¥æ”¶å›¾ç‰‡ä½œä¸ºè¾“å…¥æ¥ç”Ÿæˆæ–°å›¾ç‰‡ã€‚")

# --- åº•éƒ¨ï¼šåŸå§‹æ•°æ®æŸ¥çœ‹ ---
with st.expander("ğŸ” æŸ¥çœ‹æ‰€æœ‰æ¨¡å‹åŸå§‹æ•°æ® (JSON)"):
    if st.button("è·å– Raw Data"):
        raw_info = []
        for m in genai.list_models():
            raw_info.append({
                "name": m.name,
                "methods": m.supported_generation_methods,
                "input_limit": m.input_token_limit,
                "output_limit": m.output_token_limit
            })
        st.json(raw_info)
