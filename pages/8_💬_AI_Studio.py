import streamlit as st
from PIL import Image
import sys
import os
import google.generativeai as genai

# --- è·¯å¾„ç¯å¢ƒè®¾ç½® ---
current_script_path = os.path.abspath(__file__)
pages_dir = os.path.dirname(current_script_path)
root_dir = os.path.dirname(pages_dir)
if root_dir not in sys.path: sys.path.append(root_dir)

try:
    import auth
    from services.llm_engine import LLMEngine
    from services.image_engine import ImageGenEngine
    from app_utils.ui_components import render_chat_message
    from app_utils.image_processing import create_preview_thumbnail
except ImportError as e:
    st.error(f"âŒ æ¨¡å—ç¼ºå¤±: {e}")
    st.stop()

st.set_page_config(page_title="Amazon AI Studio", page_icon="ğŸ§ª", layout="wide")

# ==========================================
# ğŸ¨ CSS é­”æ³•åŒºï¼šæŠŠä¸Šä¼ æŒ‰é’®é’‰åœ¨èŠå¤©æ¡†æ—è¾¹
# ==========================================
st.markdown("""
<style>
    /* 1. ç»™åº•éƒ¨ç•™å‡ºç©ºé—´ï¼Œé˜²æ­¢æ¶ˆæ¯è¢«è¾“å…¥æ¡†é®æŒ¡ */
    .block-container {
        padding-bottom: 120px;
    }

    /* 2. å®šä½ä¸Šä¼ æŒ‰é’® (Popover) */
    /* åªé’ˆå¯¹ä¸»ç•Œé¢(section.main)é‡Œçš„ Popoverï¼Œä¸å½±å“ä¾§è¾¹æ  */
    section.main [data-testid="stPopover"] {
        position: fixed !important;
        bottom: 25px !important; /* è·ç¦»åº•éƒ¨ 25pxï¼Œæ­£å¥½åœ¨è¾“å…¥æ¡†å·¦ä¾§/å³ä¾§ */
        left: 20px !important;   /* é’‰åœ¨å±å¹•å·¦ä¸‹è§’ */
        z-index: 99999 !important;
        width: 45px !important;
        height: 45px !important;
    }

    /* 3. ç¾åŒ–ä¸Šä¼ æŒ‰é’®ï¼šåœ†å½¢ã€é˜´å½±ã€ç™½è‰²èƒŒæ™¯ */
    section.main [data-testid="stPopover"] > div > button {
        border-radius: 50% !important;
        width: 45px !important;
        height: 45px !important;
        background-color: #ffffff !important;
        color: #444 !important;
        border: 1px solid #e0e0e0 !important;
        box-shadow: 0 4px 10px rgba(0,0,0,0.1) !important;
        padding: 0 !important;
        display: flex !important;
        align-items: center !important;
        justify-content: center !important;
        font-size: 1.2rem !important;
        transition: all 0.2s ease !important;
    }

    /* æ‚¬åœæ•ˆæœ */
    section.main [data-testid="stPopover"] > div > button:hover {
        transform: scale(1.1) !important;
        border-color: #aaa !important;
        color: #000 !important;
    }

    /* æš—é»‘æ¨¡å¼é€‚é… */
    @media (prefers-color-scheme: dark) {
        section.main [data-testid="stPopover"] > div > button {
            background-color: #262730 !important;
            color: #fff !important;
            border: 1px solid #4a4a4a !important;
        }
    }
    
    /* éšè— Streamlit é»˜è®¤çš„ 'Deploy' æŒ‰é’®ç­‰å¹²æ‰°å…ƒç´  (å¯é€‰) */
    .stDeployButton {display:none;}
</style>
""", unsafe_allow_html=True)

# --- æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

def build_gemini_history(msgs):
    """æ„å»ºç¬¦åˆ Gemini API è§„èŒƒçš„å†å²è®°å½•"""
    history = []
    for m in msgs:
        # è¿‡æ»¤æ‰ç”Ÿå›¾ç»“æœå’Œé”™è¯¯ä¿¡æ¯ï¼Œåªä¿ç•™æ–‡æœ¬å’Œç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡
        if m["type"] == "text" or m.get("ref_images"):
            parts = []
            if m.get("ref_images"):
                parts.extend(m["ref_images"])
            if m["content"]:
                parts.append(m["content"])
            if parts:
                history.append({"role": m["role"], "parts": parts})
    return history

def delete_msg_callback(idx):
    """å›è°ƒï¼šåˆ é™¤å•æ¡æ¶ˆæ¯"""
    if 0 <= idx < len(st.session_state.studio_msgs):
        st.session_state.studio_msgs.pop(idx)
        st.rerun()

def regenerate_callback(idx):
    """å›è°ƒï¼šé‡æ–°ç”Ÿæˆ"""
    if st.session_state.studio_msgs[idx]["role"] == "model":
        st.session_state.studio_msgs.pop(idx)
        st.session_state.trigger_inference = True
        st.rerun()

# --- åˆå§‹åŒ– ---
if 'auth' in sys.modules and not auth.check_password(): st.stop()

# å®‰å…¨åˆå§‹åŒ– Session State
if "studio_msgs" not in st.session_state: st.session_state.studio_msgs = []
if "msg_uid" not in st.session_state: st.session_state.msg_uid = 0
if "uploader_key_id" not in st.session_state: st.session_state.uploader_key_id = 0
if "studio_ready" not in st.session_state:
    api_key = st.secrets.get("GOOGLE_API_KEY")
    st.session_state.llm_studio = LLMEngine(api_key)
    st.session_state.img_gen_studio = ImageGenEngine(api_key)
    st.session_state.studio_ready = True

# --- ä¾§è¾¹æ é…ç½® ---
with st.sidebar:
    st.title("ğŸ§ª AI Workbench")
    
    # æ¨¡å‹é€‰æ‹©
    model_map = {
        "ğŸ§  Gemini 3 Pro (Reasoning)": "models/gemini-3-pro-preview", 
        "âš¡ Gemini Flash (Fast)": "models/gemini-flash-latest",
        "ğŸ¨ Gemini 3 Image (Image Gen)": "models/gemini-3-pro-image-preview" 
    }
    selected_label = st.selectbox("æ ¸å¿ƒæ¨¡å‹", list(model_map.keys()))
    current_model_id = model_map[selected_label]
    is_image_mode = "image-preview" in current_model_id
    
    st.divider()
    
    # è®°å¿†ç®¡ç†åŒº
    st.caption("ğŸ§  è®°å¿†ç®¡ç†")
    col_k1, col_k2 = st.columns(2)
    with col_k1:
        if st.button("ğŸ§¹ æ¸…ç©ºå¯¹è¯", use_container_width=True):
            st.session_state.studio_msgs = []
            st.session_state.uploader_key_id += 1 
            st.toast("è®°å¿†å·²æ¸…é™¤", icon="ğŸ§¹")
            st.rerun()
    with col_k2:
        if st.button("â†©ï¸ æ’¤å›", use_container_width=True):
            if st.session_state.studio_msgs:
                st.session_state.studio_msgs.pop()
                st.rerun()

# --- æ¶ˆæ¯æ¸²æŸ“ ---
if not st.session_state.studio_msgs:
    # æ¬¢è¿é¡µ
    st.markdown("""
    <div style="text-align: center; color: #888; margin-top: 100px;">
        <h3>ğŸ‘‹ Welcome to AI Studio</h3>
        <p>ä¸Šä¼ å›¾ç‰‡ã€è¾“å…¥æŒ‡ä»¤ï¼Œå¼€å§‹ä½ çš„åˆ›ä½œã€‚</p>
    </div>
    """, unsafe_allow_html=True)
else:
    for idx, msg in enumerate(st.session_state.studio_msgs):
        render_chat_message(idx, msg, delete_msg_callback, regenerate_callback)

# --- AI æ¨ç†é€»è¾‘ ---
if st.session_state.get("trigger_inference", False):
    st.session_state.trigger_inference = False
    
    if not st.session_state.studio_msgs: st.rerun()
    last_msg = st.session_state.studio_msgs[-1]
    
    if last_msg["role"] == "user":
        with st.chat_message("model"):
            # === æ¨¡å¼ A: ç”Ÿå›¾ ===
            if is_image_mode:
                with st.status("ğŸ¨ æ­£åœ¨ç»˜åˆ¶...", expanded=True):
                    try:
                        ref_img = last_msg["ref_images"][0] if last_msg.get("ref_images") else None
                        hd_bytes = st.session_state.img_gen_studio.generate(
                            prompt=last_msg["content"],
                            model_name=current_model_id,
                            ref_image=ref_img
                        )
                        if hd_bytes:
                            thumb = create_preview_thumbnail(hd_bytes, 800)
                            st.session_state.studio_msgs.append({
                                "role": "model", "type": "image_result",
                                "content": thumb, "hd_data": hd_bytes, 
                                "id": st.session_state.msg_uid
                            })
                            st.rerun()
                        else:
                            st.error("âš ï¸ ç”Ÿæˆå¤±è´¥ (å¯èƒ½å› å®‰å…¨ç­–ç•¥æ‹¦æˆª)")
                    except Exception as e:
                        st.error(f"Generate Error: {e}")

            # === æ¨¡å¼ B: å¯¹è¯ ===
            else:
                placeholder = st.empty()
                full_resp = ""
                try:
                    past_history = build_gemini_history(st.session_state.studio_msgs[:-1])
                    chat_session = genai.GenerativeModel(current_model_id).start_chat(history=past_history)
                    
                    payload = []
                    if last_msg.get("ref_images"): payload.extend(last_msg["ref_images"])
                    if last_msg["content"]: payload.append(last_msg["content"])
                    
                    resp = chat_session.send_message(payload, stream=True)
                    for chunk in resp:
                        if chunk.text:
                            full_resp += chunk.text
                            placeholder.markdown(full_resp + "â–Œ")
                    placeholder.markdown(full_resp)
                    
                    st.session_state.msg_uid += 1
                    st.session_state.studio_msgs.append({
                        "role": "model", "type": "text", 
                        "content": full_resp, "id": st.session_state.msg_uid
                    })
                    st.rerun()
                except Exception as e:
                    st.error(f"Chat Error: {e}")

# --- åº•éƒ¨è¾“å…¥åŒº ---
if not st.session_state.get("trigger_inference", False):

    # 1. æ‚¬æµ®çš„é™„ä»¶æŒ‰é’® (ä½ç½®ç”±é¡¶éƒ¨ CSS æ§åˆ¶ï¼Œå›ºå®šåœ¨å·¦ä¸‹è§’)
    # ä½¿ç”¨åŠ¨æ€ key ç¡®ä¿å‘å®Œæ¶ˆæ¯åæ¸…ç©ºæ–‡ä»¶
    upload_key = f"uploader_{st.session_state.uploader_key_id}"
    
    with st.popover("ğŸ“", use_container_width=False):
        uploaded_files = st.file_uploader(
            "æ·»åŠ å‚è€ƒå›¾ / Add Images", 
            type=["jpg", "png", "webp"], 
            accept_multiple_files=True,
            key=upload_key
        )
        if uploaded_files:
            st.caption(f"å·²é€‰ä¸­ {len(uploaded_files)} å¼ ")

    # 2. èŠå¤©è¾“å…¥æ¡†
    user_input = st.chat_input("è¾“å…¥æŒ‡ä»¤ / Ask anything...")

    # 3. å‘é€å¤„ç†
    if user_input:
        img_list = []
        if uploaded_files:
            for uf in uploaded_files:
                img_list.append(Image.open(uf))
        
        st.session_state.msg_uid += 1
        st.session_state.studio_msgs.append({
            "role": "user",
            "type": "text",
            "content": user_input,
            "ref_images": img_list,
            "id": st.session_state.msg_uid
        })
        
        # å¼ºåˆ¶æ›´æ–° Key ä»¥æ¸…ç©ºä¸Šä¼ å™¨
        st.session_state.uploader_key_id += 1
        st.session_state.trigger_inference = True
        st.rerun()
