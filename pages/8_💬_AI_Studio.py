import streamlit as st
from PIL import Image
import sys
import os
import io
import time
import google.generativeai as genai

# --- ç¯å¢ƒé…ç½® ---
current_script_path = os.path.abspath(__file__)
pages_dir = os.path.dirname(current_script_path)
root_dir = os.path.dirname(pages_dir)
if root_dir not in sys.path:
    sys.path.append(root_dir)

try:
    import auth
    from services.llm_engine import LLMEngine
    from services.image_engine import ImageGenEngine
    # ä¿®å¤å¼•ç”¨
    from app_utils.image_processing import create_preview_thumbnail
except ImportError as e:
    st.error(f"âŒ æ ¸å¿ƒæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    st.stop()

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="Amazon AI Studio",
    page_icon="ğŸ§ª",
    layout="wide"
)

# --- CSS æ ·å¼ä¼˜åŒ– (å¯¹æ ‡ AI Studio) ---
st.markdown("""
<style>
    /* éšè—é»˜è®¤å¤´éƒ¨ */
    .block-container { padding-top: 1.5rem; }
    
    /* æ¶ˆæ¯æ°”æ³¡æ ·å¼ */
    .stChatMessage {
        background-color: transparent;
        border-bottom: 1px solid #f0f0f0;
        padding-bottom: 15px;
    }
    
    /* æ“ä½œæŒ‰é’®åŒº */
    .msg-actions {
        display: flex;
        gap: 0.5rem;
        font-size: 0.8rem;
        opacity: 0.6;
    }
    .msg-actions:hover { opacity: 1; }
    
    /* éšè—éƒ¨åˆ†Streamlité»˜è®¤å…ƒç´ ä»¥æ›´åƒApp */
    div[data-testid="stToolbar"] { visibility: hidden; }
</style>
""", unsafe_allow_html=True)

# --- 1. åˆå§‹åŒ– State ---
if 'auth' in sys.modules and not auth.check_password():
    st.stop()

# æ ¸å¿ƒæœåŠ¡
if "studio_ready" not in st.session_state:
    api_key = st.secrets.get("GOOGLE_API_KEY")
    st.session_state.llm_studio = LLMEngine(api_key)
    st.session_state.img_gen_studio = ImageGenEngine(api_key)
    st.session_state.studio_ready = True

# æ¶ˆæ¯åˆ—è¡¨ï¼šè¿™æ˜¯å”¯ä¸€çš„çœŸç†æ¥æº
# ç»“æ„: {"role": "user"/"model", "content": str/img, "type": "text"/"image_result", "hd_data": bytes, "id": int}
if "studio_msgs" not in st.session_state:
    st.session_state.studio_msgs = []

# ç¼–è¾‘çŠ¶æ€è¿½è¸ª {"idx": 3, "content": "..."}
if "editing_state" not in st.session_state:
    st.session_state.editing_state = None

# è®¡æ•°å™¨
if "msg_uid" not in st.session_state:
    st.session_state.msg_uid = 0

def get_uid():
    st.session_state.msg_uid += 1
    return st.session_state.msg_uid

# --- 2. é€»è¾‘å¤„ç†å‡½æ•° ---

def delete_msg(idx):
    """åˆ é™¤æŸæ¡æ¶ˆæ¯ï¼Œå¦‚æœæ˜¯ä¸­é—´åˆ é™¤ï¼Œå¯èƒ½éœ€è¦æˆªæ–­åç»­ä»¥ä¿æŒé€»è¾‘è¿è´¯(å¯é€‰)ï¼Œè¿™é‡Œé€‰æ‹©ä»…åˆ é™¤è¯¥æ¡"""
    if 0 <= idx < len(st.session_state.studio_msgs):
        st.session_state.studio_msgs.pop(idx)
        st.rerun()

def start_edit(idx, content):
    """è¿›å…¥ç¼–è¾‘æ¨¡å¼"""
    st.session_state.editing_state = {"idx": idx, "content": content}
    st.rerun()

def save_edit(idx, new_content):
    """ä¿å­˜ç¼–è¾‘ï¼šé€šå¸¸æ„å‘³ç€æˆªæ–­åç»­å†å²ï¼Œé‡æ–°ç”Ÿæˆ"""
    # 1. æ›´æ–°è¯¥æ¡å†…å®¹
    st.session_state.studio_msgs[idx]["content"] = new_content
    # 2. æˆªæ–­ï¼šç¼–è¾‘äº†ç”¨æˆ·çš„ Promptï¼Œé€šå¸¸æ„å‘³ç€åé¢çš„ AI å›å¤ä½œåºŸ
    st.session_state.studio_msgs = st.session_state.studio_msgs[:idx+1]
    # 3. é€€å‡ºç¼–è¾‘
    st.session_state.editing_state = None
    # 4. è§¦å‘é‡æ–°ç”Ÿæˆ (é€šè¿‡è®¾ç½®æ ‡è®°è®©ä¸»å¾ªç¯å¤„ç†)
    st.session_state.trigger_inference = True
    st.rerun()

def cancel_edit():
    st.session_state.editing_state = None
    st.rerun()

def regenerate(idx):
    """é‡ç”Ÿæˆï¼šåˆ é™¤è¿™æ¡ AI å›å¤ï¼Œå¹¶è§¦å‘ä¸Šä¸€æ¡ User æ¶ˆæ¯çš„æ¨ç†"""
    # ç¡®ä¿è¿™æ¡æ˜¯ assistant æ¶ˆæ¯
    if st.session_state.studio_msgs[idx]["role"] == "model":
        # åˆ é™¤å½“å‰æ¡
        st.session_state.studio_msgs.pop(idx)
        # è§¦å‘æ¨ç†
        st.session_state.trigger_inference = True
        st.rerun()

def build_gemini_history(msgs):
    """å°† UI æ¶ˆæ¯è½¬æ¢ä¸º Gemini API æ ¼å¼"""
    history = []
    for m in msgs:
        if m["type"] == "text" or m.get("ref_image"):
            parts = []
            if m.get("ref_image"):
                parts.append(m["ref_image"])
            if m["content"]:
                parts.append(m["content"])
            
            if parts:
                history.append({
                    "role": m["role"],
                    "parts": parts
                })
    return history

# --- 3. ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("ğŸ§ª AI Studio")
    
    # æ¨¡å‹é€‰æ‹©
    model_map = {
        "âš¡ Gemini Flash (Fast)": "models/gemini-flash-latest",
        "ğŸ§  Gemini 3 Pro (Reasoning)": "models/gemini-3-pro-preview", 
        "ğŸ¨ Gemini 3 Image (Image Gen)": "models/gemini-3-pro-image-preview" 
    }
    
    selected_label = st.selectbox("Select Model", list(model_map.keys()), label_visibility="collapsed")
    current_model_id = model_map[selected_label]
    is_image_mode = "image-preview" in current_model_id

    st.divider()

    if is_image_mode:
        st.caption("ğŸ¨ Generation Settings")
        ratio = st.selectbox("Aspect Ratio", ["1:1 (Square)", "4:3", "3:4", "16:9", "9:16"])
        seed_val = st.number_input("Seed (-1 Random)", value=-1)
    else:
        st.caption("ğŸ§  System Instructions")
        sys_prompt = st.text_area("System Prompt", value="You are a helpful Amazon assistant.", height=150)

    st.divider()
    if st.button("ğŸ—‘ï¸ Clear All History", type="primary", use_container_width=True):
        st.session_state.studio_msgs = []
        st.rerun()

# --- 4. ä¸»å·¥ä½œå° (å†å²æ¶ˆæ¯æ¸²æŸ“) ---
chat_container = st.container()

with chat_container:
    for idx, msg in enumerate(st.session_state.studio_msgs):
        
        # åˆ¤æ–­æ˜¯å¦æ­£åœ¨ç¼–è¾‘è¿™æ¡æ¶ˆæ¯
        is_editing = (st.session_state.editing_state and st.session_state.editing_state["idx"] == idx)
        
        with st.chat_message(msg["role"]):
            
            # === ç¼–è¾‘æ¨¡å¼è§†å›¾ ===
            if is_editing:
                edit_col1, edit_col2 = st.columns([4, 1])
                with edit_col1:
                    new_val = st.text_area("Edit prompt:", value=msg["content"], label_visibility="collapsed")
                with edit_col2:
                    if st.button("Save & Run", key=f"save_{msg['id']}"):
                        save_edit(idx, new_val)
                    if st.button("Cancel", key=f"cancel_{msg['id']}"):
                        cancel_edit()
            
            # === æ­£å¸¸è§†å›¾ ===
            else:
                # 1. æ˜¾ç¤ºå†…å®¹
                if msg.get("ref_image"):
                    st.image(msg["ref_image"], width=200)
                
                if msg["type"] == "image_result":
                    # è¿™é‡Œçš„ content å·²ç»æ˜¯ç¼©ç•¥å›¾äº†ï¼Œç›´æ¥æ˜¾ç¤º
                    st.image(msg["content"], caption=f"Generated Image", width=400)
                else:
                    st.markdown(msg["content"])
                
                # 2. æ“ä½œæ  (Action Bar) - æ¨¡ä»¿ Google AI Studio æ”¾åœ¨æ¶ˆæ¯ä¸‹æ–¹
                # ä½¿ç”¨ columns å¸ƒå±€æ“ä½œæŒ‰é’®
                act_cols = st.columns([0.1, 0.1, 0.1, 0.1, 0.6])
                
                # æŒ‰é’®A: ç¼–è¾‘ (ä»…ç”¨æˆ·)
                if msg["role"] == "user":
                    with act_cols[0]:
                        if st.button("âœï¸", key=f"edit_{msg['id']}", help="Edit prompt"):
                            start_edit(idx, msg["content"])
                
                # æŒ‰é’®B: é‡ç”Ÿæˆ (ä»… AI)
                if msg["role"] == "model":
                    with act_cols[0]:
                        if st.button("ğŸ”„", key=f"regen_{msg['id']}", help="Regenerate"):
                            regenerate(idx)
                
                # æŒ‰é’®C: ä¸‹è½½ (ä»…å›¾ç‰‡)
                if msg["type"] == "image_result" and msg.get("hd_data"):
                    with act_cols[1]:
                        st.download_button(
                            "â¬‡ï¸", 
                            data=msg["hd_data"], 
                            file_name=f"gen_{msg['id']}.jpg", 
                            mime="image/jpeg", 
                            key=f"dl_{msg['id']}",
                            help="Download HD Image"
                        )
                
                # æŒ‰é’®D: åˆ é™¤ (é€šç”¨)
                # è°ƒæ•´ä½ç½®ï¼šå¦‚æœæ˜¯ AI æ¶ˆæ¯æ”¾åœ¨ç¬¬äºŒåˆ—ï¼Œç”¨æˆ·æ¶ˆæ¯æ”¾åœ¨ç¬¬äºŒåˆ—
                del_col_idx = 2 if (msg["type"] == "image_result" or msg["role"]=="model") else 1
                with act_cols[del_col_idx]:
                    if st.button("ğŸ—‘ï¸", key=f"del_{msg['id']}", help="Delete this message"):
                        delete_msg(idx)

# --- 5. æ¨ç†é€»è¾‘ (Trigger Inference) ---
# å½“ç”¨æˆ·è¾“å…¥ã€æˆ–ç‚¹å‡»"Save & Run"ã€æˆ–ç‚¹å‡»"Regenerate"æ—¶ï¼Œtrigger_inference ä¼šè¢«è®¾ä¸º True
if st.session_state.get("trigger_inference", False):
    # ç«‹å³å¤ä½æ ‡è®°
    st.session_state.trigger_inference = False
    
    # è·å–ä¸Šä¸‹æ–‡ï¼ˆæœ€åä¸€æ¡é€šå¸¸æ˜¯ User çš„ Promptï¼‰
    if not st.session_state.studio_msgs:
        st.stop()
        
    last_msg = st.session_state.studio_msgs[-1]
    
    # å¿…é¡»ä¿è¯æœ€åä¸€æ¡æ˜¯ User å‘èµ·çš„ï¼Œæ‰èƒ½è®© AI å›å¤
    if last_msg["role"] == "user":
        
        with st.chat_message("model"):
            
            # === ç”Ÿå›¾æ¨¡å¼ ===
            if is_image_mode:
                with st.status("ğŸ¨ Rendering...", expanded=True) as status:
                    try:
                        # æ ¸å¿ƒç”Ÿå›¾è°ƒç”¨
                        hd_bytes = st.session_state.img_gen_studio.generate(
                            prompt=last_msg["content"],
                            model_name=current_model_id,
                            ref_image=last_msg.get("ref_image"),
                            ratio_suffix=f", aspect ratio {ratio.split()[0]}",
                            seed=int(seed_val) if seed_val != -1 else None
                        )
                        
                        if hd_bytes:
                            # 1. ä¿®å¤çš„ç¼©ç•¥å›¾è°ƒç”¨ (ä¸ä½¿ç”¨å…³é”®å­— size=)
                            thumb = create_preview_thumbnail(hd_bytes, 800)
                            
                            # 2. è¿½åŠ åˆ°å†å²
                            st.session_state.studio_msgs.append({
                                "role": "model",
                                "type": "image_result",
                                "content": thumb,   # é¢„è§ˆå›¾
                                "hd_data": hd_bytes, # é«˜æ¸…åŸå›¾
                                "id": get_uid()
                            })
                            status.update(label="Complete", state="complete")
                            st.rerun()
                        else:
                            st.error("Safety filter triggered or error occurred.")
                            status.update(label="Failed", state="error")
                    except Exception as e:
                        st.error(f"Gen Error: {e}")

            # === æ–‡æœ¬/å¯¹è¯æ¨¡å¼ ===
            else:
                placeholder = st.empty()
                full_resp = ""
                
                try:
                    # 1. åŠ¨æ€é‡å»ºå†å² (Stateless æ¨¡å¼ï¼Œä¿è¯ä¸Šä¸‹æ–‡æ°¸è¿œæ­£ç¡®)
                    # å–å‡ºé™¤äº†æœ€åä¸€æ¡çš„æ‰€æœ‰å†å²ä½œä¸º context
                    past_msgs = st.session_state.studio_msgs[:-1]
                    gemini_history = build_gemini_history(past_msgs)
                    
                    # 2. åˆå§‹åŒ–å¸¦ System Prompt çš„æ¨¡å‹
                    model = st.session_state.llm_studio.get_chat_model(current_model_id, sys_prompt)
                    chat = model.start_chat(history=gemini_history)
                    
                    # 3. å‘é€æœ€åä¸€æ¡æ¶ˆæ¯
                    user_content = []
                    if last_msg.get("ref_image"): user_content.append(last_msg["ref_image"])
                    if last_msg["content"]: user_content.append(last_msg["content"])
                    
                    response = chat.send_message(user_content, stream=True)
                    
                    for chunk in response:
                        if chunk.text:
                            full_resp += chunk.text
                            placeholder.markdown(full_resp + "â–Œ")
                    
                    placeholder.markdown(full_resp)
                    
                    # 4. è¿½åŠ ç»“æœ
                    st.session_state.studio_msgs.append({
                        "role": "model",
                        "type": "text",
                        "content": full_resp,
                        "id": get_uid()
                    })
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"Chat Error: {e}")

# --- 6. åº•éƒ¨è¾“å…¥æ¡† ---
# åªæœ‰ä¸åœ¨æ¨ç†æ—¶æ‰æ˜¾ç¤º
if not st.session_state.get("trigger_inference", False):
    
    # æ–‡ä»¶ä¸Šä¼ åŒº
    with st.expander("ğŸ“· Add Image", expanded=False):
        uploaded_file = st.file_uploader("Upload", type=["jpg", "png", "webp"], label_visibility="collapsed")
    
    user_input = st.chat_input("Message Amazon AI Studio...")

    if user_input:
        img_obj = Image.open(uploaded_file) if uploaded_file else None
        
        # å­˜å…¥å†å²
        st.session_state.studio_msgs.append({
            "role": "user",
            "type": "text",
            "content": user_input,
            "ref_image": img_obj,
            "id": get_uid()
        })
        
        # è®¾ç½®æ ‡è®°ï¼Œä¸‹ä¸€å¸§è§¦å‘æ¨ç†
        st.session_state.trigger_inference = True
        st.rerun()
