import streamlit as st
from PIL import Image
import sys
import os
import io

# --- è·¯å¾„ç¯å¢ƒè®¾ç½® ---
current_script_path = os.path.abspath(__file__)
pages_dir = os.path.dirname(current_script_path)
root_dir = os.path.dirname(pages_dir)
if root_dir not in sys.path:
    sys.path.append(root_dir)

try:
    import auth
    from services.llm_engine import LLMEngine
    from services.image_engine import ImageGenEngine
    # å¼•å…¥æ ¸å¿ƒUIç»„ä»¶
    from app_utils.image_processing import create_preview_thumbnail
    from app_utils.ui_components import show_image_modal
except ImportError as e:
    st.error(f"âŒ æ ¸å¿ƒæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    st.stop()

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="Amazon AI Studio",
    page_icon="ğŸ’¬",
    layout="wide"
)

# --- CSS æ·±åº¦ä¼˜åŒ– ---
st.markdown("""
<style>
    /* 1. è§£å†³æ»šåŠ¨å›å¼¹: ç§»é™¤å¤šä½™çš„paddingï¼Œè®©å†…å®¹è‡ªç„¶æµå¼æ’åˆ— */
    .block-container { padding-top: 1rem; padding-bottom: 8rem; }
    
    /* 2. æ¶ˆæ¯æ°”æ³¡ç¾åŒ– */
    .stChatMessage {
        background-color: transparent;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 0.5rem;
    }
    .stChatMessage:hover {
        background-color: rgba(240, 242, 246, 0.5); /* é¼ æ ‡æ‚¬åœå¾®é«˜äº® */
    }

    /* 3. æ“ä½œæ æ ·å¼ */
    .msg-actions {
        display: flex;
        gap: 8px;
        margin-top: 5px;
        opacity: 0.4;
        transition: opacity 0.2s;
    }
    .stChatMessage:hover .msg-actions { opacity: 1; }
    
    /* 4. å›¾ç‰‡å®¹å™¨é™åˆ¶ */
    .preview-img {
        border-radius: 8px;
        border: 1px solid #ddd;
    }
</style>
""", unsafe_allow_html=True)

# --- 1. åˆå§‹åŒ– State ---
if 'auth' in sys.modules and not auth.check_password():
    st.stop()

if "studio_ready" not in st.session_state:
    api_key = st.secrets.get("GOOGLE_API_KEY")
    st.session_state.llm_studio = LLMEngine(api_key)
    st.session_state.img_gen_studio = ImageGenEngine(api_key)
    st.session_state.studio_ready = True

# æ¶ˆæ¯å†å²
if "studio_msgs" not in st.session_state:
    st.session_state.studio_msgs = []

# ç¼–è¾‘çŠ¶æ€
if "editing_state" not in st.session_state:
    st.session_state.editing_state = None

# ID è®¡æ•°å™¨
if "msg_uid" not in st.session_state:
    st.session_state.msg_uid = 0

def get_uid():
    st.session_state.msg_uid += 1
    return st.session_state.msg_uid

# --- 2. é€»è¾‘å‡½æ•° ---

def delete_msg(idx):
    if 0 <= idx < len(st.session_state.studio_msgs):
        st.session_state.studio_msgs.pop(idx)
        st.rerun()

def start_edit(idx, content):
    st.session_state.editing_state = {"idx": idx, "content": content}
    st.rerun()

def save_edit(idx, new_content):
    st.session_state.studio_msgs[idx]["content"] = new_content
    # æˆªæ–­åç»­
    st.session_state.studio_msgs = st.session_state.studio_msgs[:idx+1]
    st.session_state.editing_state = None
    st.session_state.trigger_inference = True
    st.rerun()

def cancel_edit():
    st.session_state.editing_state = None
    st.rerun()

def regenerate(idx):
    if st.session_state.studio_msgs[idx]["role"] == "model":
        st.session_state.studio_msgs.pop(idx)
        st.session_state.trigger_inference = True
        st.rerun()

def build_gemini_history(msgs):
    history = []
    for m in msgs:
        if m["type"] == "text" or m.get("ref_image"):
            parts = []
            if m.get("ref_image"): parts.append(m["ref_image"])
            if m["content"]: parts.append(m["content"])
            if parts:
                history.append({"role": m["role"], "parts": parts})
    return history

# --- 3. ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("ğŸ§ª AI Workbench")
    
    model_map = {
        "âš¡ Gemini Flash (Fast)": "models/gemini-flash-latest",
        "ğŸ§  Gemini 3 Pro (Reasoning)": "models/gemini-3-pro-preview", 
        "ğŸ¨ Gemini 3 Image (Image Gen)": "models/gemini-3-pro-image-preview" 
    }
    
    selected_label = st.selectbox("Select Model", list(model_map.keys()), label_visibility="collapsed")
    current_model_id = model_map[selected_label]
    is_image_mode = "image-preview" in current_model_id

    st.divider()

    if is_image_mode:
        st.caption("ğŸ¨ Image Settings")
        ratio = st.selectbox("Aspect Ratio", ["1:1 (Square)", "4:3", "3:4", "16:9", "9:16"])
        seed_val = st.number_input("Seed (-1 Random)", value=-1)
    else:
        st.caption("ğŸ§  Persona")
        sys_prompt = st.text_area("System Prompt", value="You are a helpful Amazon assistant.", height=150)

    st.divider()
    if st.button("ğŸ—‘ï¸ New Chat", use_container_width=True):
        st.session_state.studio_msgs = []
        st.rerun()

# --- 4. ä¸»æ¶ˆæ¯åŒº (ç§»é™¤ st.container ä»¥è§£å†³æ»šåŠ¨ Bug) ---

# ç›´æ¥åœ¨ä¸»æµç¨‹æ¸²æŸ“ï¼Œè®© Streamlit è‡ªåŠ¨å¤„ç†æ»šåŠ¨
for idx, msg in enumerate(st.session_state.studio_msgs):
    is_editing = (st.session_state.editing_state and st.session_state.editing_state["idx"] == idx)
    
    with st.chat_message(msg["role"]):
        
        # === ç¼–è¾‘æ¨¡å¼ ===
        if is_editing:
            new_val = st.text_area("Edit prompt:", value=msg["content"], height=100)
            c1, c2 = st.columns([1, 4])
            if c1.button("Save", key=f"s_{msg['id']}"): save_edit(idx, new_val)
            if c2.button("Cancel", key=f"c_{msg['id']}"): cancel_edit()
        
        # === æµè§ˆæ¨¡å¼ ===
        else:
            # 1. å«å›¾æ˜¾ç¤º
            if msg.get("ref_image"):
                st.image(msg["ref_image"], width=150, caption="Ref Image")
            
            # 2. å†…å®¹æ˜¾ç¤º (æ ¸å¿ƒä¿®æ”¹ç‚¹ï¼šSmart Edit é£æ ¼é¢„è§ˆ)
            if msg["type"] == "image_result":
                # æ˜¾ç¤ºç¼©ç•¥å›¾ (å¿«é€Ÿ)
                st.image(msg["content"], width=400)
                
                # æ“ä½œåŒº (æ”¾å¤§ + ä¸‹è½½)
                act_cols = st.columns([1, 1, 4])
                with act_cols[0]:
                    # æ¨¡æ€æ¡†é€»è¾‘
                    if st.button("ğŸ” Zoom", key=f"zoom_{msg['id']}"):
                        show_image_modal(msg["hd_data"], f"Result-{msg['id']}")
                with act_cols[1]:
                    # ä¸‹è½½æŒ‰é’®
                    st.download_button(
                        "ğŸ“¥", 
                        data=msg["hd_data"], 
                        file_name=f"gen_{msg['id']}.jpg", 
                        mime="image/jpeg", 
                        key=f"dl_{msg['id']}"
                    )
                with act_cols[2]:
                     if st.button("ğŸ—‘ï¸", key=f"del_img_{msg['id']}"): delete_msg(idx)

            else:
                st.markdown(msg["content"])
                
                # æ–‡æœ¬æ¶ˆæ¯çš„æ“ä½œæ 
                # ä½¿ç”¨ opacity CSS å®ç°é¼ æ ‡æ‚¬åœæ‰æ˜¾ç¤º
                st.markdown('<div class="msg-actions">', unsafe_allow_html=True)
                
                act_c1, act_c2, _ = st.columns([1, 1, 8])
                
                # ç¼–è¾‘æŒ‰é’® (ä»…ç”¨æˆ·)
                if msg["role"] == "user":
                    with act_c1:
                        if st.button("âœï¸", key=f"edt_{msg['id']}"): start_edit(idx, msg["content"])
                
                # é‡è¯•æŒ‰é’® (ä»… AI)
                if msg["role"] == "model":
                    with act_c1:
                        if st.button("ğŸ”„", key=f"rgn_{msg['id']}"): regenerate(idx)
                
                # åˆ é™¤æŒ‰é’® (é€šç”¨)
                with act_c2:
                    if st.button("ğŸ—‘ï¸", key=f"del_{msg['id']}"): delete_msg(idx)
                    
                st.markdown('</div>', unsafe_allow_html=True)

# åº•éƒ¨å ä½ç¬¦ï¼Œé˜²æ­¢å†…å®¹è¢«è¾“å…¥æ¡†é®æŒ¡
st.markdown("<div style='height: 100px;'></div>", unsafe_allow_html=True)

# --- 5. æ¨ç†é€»è¾‘ ---
if st.session_state.get("trigger_inference", False):
    st.session_state.trigger_inference = False
    
    if not st.session_state.studio_msgs: st.stop()
    last_msg = st.session_state.studio_msgs[-1]
    
    if last_msg["role"] == "user":
        with st.chat_message("model"):
            if is_image_mode:
                with st.status("ğŸ¨ Rendering...", expanded=True):
                    try:
                        hd_bytes = st.session_state.img_gen_studio.generate(
                            prompt=last_msg["content"],
                            model_name=current_model_id,
                            ref_image=last_msg.get("ref_image"),
                            ratio_suffix=f", aspect ratio {ratio.split()[0]}",
                            seed=int(seed_val) if seed_val != -1 else None
                        )
                        if hd_bytes:
                            # ç”Ÿæˆç¼©ç•¥å›¾
                            thumb = create_preview_thumbnail(hd_bytes, 800)
                            st.session_state.studio_msgs.append({
                                "role": "model", "type": "image_result",
                                "content": thumb, "hd_data": hd_bytes, "id": get_uid()
                            })
                            st.rerun()
                        else:
                            st.error("Blocked by safety filters.")
                    except Exception as e:
                        st.error(f"Error: {e}")
            else:
                # æ–‡æœ¬é€»è¾‘ (åŒå‰)
                try:
                    placeholder = st.empty()
                    full_resp = ""
                    past_msgs = st.session_state.studio_msgs[:-1]
                    gemini_history = build_gemini_history(past_msgs)
                    model = st.session_state.llm_studio.get_chat_model(current_model_id, sys_prompt)
                    chat = model.start_chat(history=gemini_history)
                    
                    user_c = []
                    if last_msg.get("ref_image"): user_c.append(last_msg["ref_image"])
                    if last_msg["content"]: user_c.append(last_msg["content"])
                    
                    response = chat.send_message(user_c, stream=True)
                    for chunk in response:
                        if chunk.text:
                            full_resp += chunk.text
                            placeholder.markdown(full_resp + "â–Œ")
                    placeholder.markdown(full_resp)
                    st.session_state.studio_msgs.append({
                        "role": "model", "type": "text",
                        "content": full_resp, "id": get_uid()
                    })
                    st.rerun()
                except Exception as e:
                    st.error(f"Error: {e}")

# --- 6. åº•éƒ¨è¾“å…¥åŒº (ä¼˜åŒ–ç‰ˆ) ---
if not st.session_state.get("trigger_inference", False):
    
    # å¸ƒå±€ä¼˜åŒ–ï¼šåˆ©ç”¨ Popover å®ç°ç±»ä¼¼â€œé™„ä»¶èœå•â€çš„æ•ˆæœ
    # è¿™ä¼šæ˜¾ç¤ºåœ¨è¾“å…¥æ¡†çš„å·¦ä¸Šæ–¹ï¼Œæœ€æ¥è¿‘ "æ—è¾¹" çš„æ•ˆæœ
    
    # å®šä¹‰åº•éƒ¨å®¹å™¨ï¼Œå›ºå®šåœ¨ä¸‹æ–¹
    bottom_container = st.container()
    
    with bottom_container:
        # åˆ›å»ºä¸¤åˆ—ï¼šå·¦ä¾§æ˜¯é™„ä»¶æŒ‰é’®ï¼Œå³ä¾§ç”±äº chat_input ç‹¬å ä¸€è¡Œï¼Œå…¶å®è¿™é‡Œä¸»è¦æ˜¯ç»™é™„ä»¶è…¾ä½ç½®
        
        # ä½¿ç”¨ st.popover åˆ›å»ºä¸€ä¸ªæŠ˜å çš„èœå•
        with st.popover("ğŸ“ æ·»åŠ å›¾ç‰‡", use_container_width=False):
            uploaded_file = st.file_uploader(
                "Upload Reference Image", 
                type=["jpg", "png", "webp"], 
                key="chat_uploader"
            )
            if uploaded_file:
                st.caption("âœ… å›¾ç‰‡å·²å°±ç»ªï¼Œè¯·åœ¨ä¸‹æ–¹å‘é€")

        # ç´§æ¥ç€æ˜¯è¾“å…¥æ¡†
        user_input = st.chat_input("Message...")

    if user_input:
        img_obj = Image.open(uploaded_file) if uploaded_file else None
        
        st.session_state.studio_msgs.append({
            "role": "user",
            "type": "text",
            "content": user_input,
            "ref_image": img_obj,
            "id": get_uid()
        })
        st.session_state.trigger_inference = True
        st.rerun()
