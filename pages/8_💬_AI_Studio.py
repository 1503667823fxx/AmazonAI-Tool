import streamlit as st
from PIL import Image
import sys
import os
import io

# --- è·¯å¾„ç¯å¢ƒè®¾ç½® ---
current_script_path = os.path.abspath(__file__)
pages_dir = os.path.dirname(current_script_path)
root_dir = os.path.dirname(pages_dir)
if root_dir not in sys.path:
    sys.path.append(root_dir)

try:
    import auth
    from services.llm_engine import LLMEngine
    from services.image_engine import ImageGenEngine
    # å¤ç”¨ä½ é¡¹ç›®é‡Œçš„å›¾ç‰‡å¤„ç†å·¥å…·
    from app_utils.image_processing import create_preview_thumbnail
except ImportError as e:
    st.error(f"âŒ æ ¸å¿ƒæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    st.stop()

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="AI Studio Workbench", 
    page_icon="ğŸ§ª", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS æ ·å¼æ³¨å…¥ (æ¨¡ä»¿ Google AI Studio) ---
st.markdown("""
<style>
    /* éšè—é¡¶éƒ¨Padding */
    .block-container { padding-top: 2rem; }
    
    /* æ¶ˆæ¯æ°”æ³¡å¾®è°ƒ */
    .stChatMessage { 
        background-color: transparent; 
        border-radius: 10px;
    }

    /* æ“ä½œæŒ‰é’®è¡Œæ ·å¼ */
    .action-row {
        display: flex; 
        gap: 10px; 
        margin-top: -10px; 
        margin-bottom: 20px;
        opacity: 0.7;
    }
    .action-row:hover { opacity: 1; }
</style>
""", unsafe_allow_html=True)

# --- 1. åˆå§‹åŒ–ä¸é‰´æƒ ---
if 'auth' in sys.modules and not auth.check_password():
    st.stop()

if "studio_ready" not in st.session_state:
    api_key = st.secrets.get("GOOGLE_API_KEY")
    st.session_state.llm_studio = LLMEngine(api_key)
    st.session_state.img_gen_studio = ImageGenEngine(api_key)
    st.session_state.studio_ready = True

# æ¶ˆæ¯ç»“æ„: [{"role": "user", "type": "text/image/gen_result", "content": "...", "hd_data": bytes, "id": 0}]
if "studio_msgs" not in st.session_state:
    st.session_state.studio_msgs = []

# å…¨å±€è®¡æ•°å™¨ç”¨äºç”Ÿæˆå”¯ä¸€ Key
if "msg_counter" not in st.session_state:
    st.session_state.msg_counter = 0

# --- 2. è¾…åŠ©å‡½æ•° ---
def delete_message(index):
    """åˆ é™¤æŒ‡å®šç´¢å¼•çš„æ¶ˆæ¯"""
    if 0 <= index < len(st.session_state.studio_msgs):
        st.session_state.studio_msgs.pop(index)
        # æ³¨æ„ï¼šè¿™é‡Œä»…åˆ é™¤äº†UIæ˜¾ç¤ºã€‚
        # å¦‚æœéœ€è¦åŒæ­¥åˆ é™¤ Gemini åç«¯è®°å¿†ï¼Œéœ€è¦é‡å»º Chat Sessionï¼Œè€ƒè™‘åˆ°æ€§èƒ½æš‚ä¸åšå¤æ‚å¤„ç†ã€‚
        # å¯¹äº"ç”Ÿå›¾"æˆ–"å•è½®é—®ç­”"åœºæ™¯ï¼ŒUIåˆ é™¤å·²è¶³å¤Ÿã€‚

def add_message(role, content, msg_type="text", hd_data=None, ref_image=None):
    """ç»Ÿä¸€æ·»åŠ æ¶ˆæ¯åˆ°å†å²"""
    st.session_state.studio_msgs.append({
        "role": role,
        "type": msg_type,
        "content": content,     # æ–‡æœ¬å†…å®¹ æˆ– ç¼©ç•¥å›¾å¯¹è±¡
        "hd_data": hd_data,     # åŸå§‹é«˜æ¸…æ•°æ® (ä»…ç”Ÿå›¾ç»“æœæœ‰)
        "ref_image": ref_image, # ç”¨æˆ·ä¸Šä¼ çš„å«å›¾
        "id": st.session_state.msg_counter
    })
    st.session_state.msg_counter += 1

# --- 3. ä¾§è¾¹æ  (å·¥ä½œå°è®¾ç½®) ---
with st.sidebar:
    st.title("ğŸ§ª AI Studio")
    
    # æ¨¡å‹é€‰æ‹©
    model_map = {
        "âš¡ Gemini Flash (Fast)": "models/gemini-flash-latest",
        "ğŸ§  Gemini 3 Pro (Reasoning)": "models/gemini-3-pro-preview", 
        "ğŸ¨ Gemini 3 Image (Generation)": "models/gemini-3-pro-image-preview" 
    }
    
    selected_label = st.selectbox("Model", list(model_map.keys()), label_visibility="collapsed")
    current_model_id = model_map[selected_label]
    is_image_mode = "image-preview" in current_model_id

    st.divider()

    # å‚æ•°åŒº
    if is_image_mode:
        st.caption("âš™ï¸ Generation Params")
        ratio = st.selectbox("Aspect Ratio", ["1:1", "4:3", "3:4", "16:9"], index=0)
        seed_val = st.number_input("Seed", value=-1)
    else:
        st.caption("âš™ï¸ System Instructions")
        sys_prompt = st.text_area("System Prompt", value="ä½ æ˜¯ä¸€ä¸ªäºšé©¬é€Šç”µå•†ä¸“å®¶ã€‚", height=150)

    st.divider()
    
    # å…¨å±€æ¸…ç©º
    if st.button("ğŸ—‘ï¸ Clear Context", use_container_width=True):
        st.session_state.studio_msgs = []
        # å¦‚æœæ˜¯æ–‡æœ¬å¯¹è¯ï¼Œé‡ç½® Session
        if not is_image_mode:
             model = st.session_state.llm_studio.get_chat_model(current_model_id, sys_prompt)
             st.session_state.gemini_chat = model.start_chat(history=[])
        st.rerun()

# --- 4. ä¸»å·¥ä½œåŒº (æ¸²æŸ“å†å²æ¶ˆæ¯) ---
# ä½¿ç”¨ container åŒ…è£¹ï¼Œé˜²æ­¢åº•éƒ¨è¾“å…¥æ¡†è·³åŠ¨
chat_container = st.container()

with chat_container:
    # éå†æ—¶éœ€è¦ index ç”¨äºåˆ é™¤
    for idx, msg in enumerate(st.session_state.studio_msgs):
        
        # 1. æ¸²æŸ“æ¶ˆæ¯ä¸»ä½“
        with st.chat_message(msg["role"]):
            
            # Case A: ç”¨æˆ·æ¶ˆæ¯ (å«å«å›¾)
            if msg["role"] == "user":
                if msg.get("ref_image"):
                    # æ˜¾ç¤ºä¸Šä¼ å›¾çš„ç¼©ç•¥ç‰ˆæœ¬
                    st.image(msg["ref_image"], width=200)
                st.write(msg["content"])
            
            # Case B: AI ç”Ÿå›¾ç»“æœ (é¢„è§ˆå›¾ + é«˜æ¸…ä¸‹è½½)
            elif msg["type"] == "image_result":
                # æ˜¾ç¤ºé¢„è§ˆå›¾ (Content å­˜çš„æ˜¯ PIL æˆ– ç¼©ç•¥å›¾)
                st.image(msg["content"], width=400, caption="Preview Version")
                
                # --- æ“ä½œæ  (Action Row) ---
                col_act1, col_act2, col_act3 = st.columns([1, 1, 3])
                with col_act1:
                    # ä¸‹è½½æŒ‰é’® (ä½¿ç”¨é«˜æ¸…æ•°æ®)
                    if msg.get("hd_data"):
                        filename = f"studio_gen_{msg['id']}.jpg"
                        st.download_button(
                            label="ğŸ“¥ HD Download",
                            data=msg["hd_data"],
                            file_name=filename,
                            mime="image/jpeg",
                            key=f"dl_{msg['id']}"
                        )
                with col_act2:
                    # åˆ é™¤æŒ‰é’®
                    if st.button("ğŸ—‘ï¸ Delete", key=f"del_btn_{msg['id']}"):
                        delete_message(idx)
                        st.rerun()

            # Case C: AI æ–‡æœ¬å›å¤
            else:
                st.write(msg["content"])
                # æ–‡æœ¬æ¶ˆæ¯ä¹Ÿå¯ä»¥æœ‰åˆ é™¤æŒ‰é’® (æ”¾åœ¨å³ä¸‹è§’æˆ–ä¸‹æ–¹)
                if st.button("âœ•", key=f"del_txt_{msg['id']}", help="Remove this message"):
                    delete_message(idx)
                    st.rerun()

    st.write("") # Spacer

# --- 5. åº•éƒ¨è¾“å…¥åŒº ---
uploaded_file = st.file_uploader("Upload Image", type=["jpg", "png", "webp"], label_visibility="collapsed")
user_input = st.chat_input("Type your instructions here...")

if user_input:
    # 1. å¤„ç†ç”¨æˆ·è¾“å…¥
    input_image = None
    if uploaded_file:
        input_image = Image.open(uploaded_file)
    
    # æ·»åŠ åˆ° UI å†å²
    add_message("user", user_input, ref_image=input_image)
    st.rerun() # å¼ºåˆ¶åˆ·æ–°ä»¥ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯ï¼Œç„¶åå¼€å§‹ AI æ€è€ƒ

# --- 6. å¼‚æ­¥å¤„ç† AI å“åº” (åˆ©ç”¨ Session State æ£€æµ‹æ–°æ¶ˆæ¯) ---
# é€»è¾‘ï¼šå¦‚æœæœ€åä¸€æ¡æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œåˆ™è§¦å‘ AI
if st.session_state.studio_msgs and st.session_state.studio_msgs[-1]["role"] == "user":
    last_msg = st.session_state.studio_msgs[-1]
    last_text = last_msg["content"]
    last_img = last_msg.get("ref_image")

    with st.chat_message("assistant"):
        
        # === æ¨¡å¼ A: ç”Ÿå›¾ ===
        if is_image_mode:
            with st.status("ğŸ¨ Generating Image...", expanded=True) as status:
                try:
                    # è·å–é«˜æ¸… Byte æµ
                    hd_bytes = st.session_state.img_gen_studio.generate(
                        prompt=last_text,
                        model_name=current_model_id,
                        ref_image=last_img,
                        ratio_suffix=f", aspect ratio {ratio.split()[0]}",
                        seed=int(seed_val) if seed_val != -1 else None
                    )
                    
                    if hd_bytes:
                        # 1. ç”Ÿæˆé¢„è§ˆç¼©ç•¥å›¾ (åŠ å¿«æ¸²æŸ“)
                        preview_img = create_preview_thumbnail(hd_bytes, size=800) 
                        
                        # 2. å­˜å…¥å†å²
                        add_message(
                            "assistant", 
                            content=preview_img,  # å­˜é¢„è§ˆå›¾ç”¨äºæ˜¾ç¤º
                            msg_type="image_result",
                            hd_data=hd_bytes      # å­˜åŸå§‹æ•°æ®ç”¨äºä¸‹è½½
                        )
                        status.update(label="Done!", state="complete")
                        st.rerun() # åˆ·æ–°æ˜¾ç¤ºç»“æœå’ŒæŒ‰é’®
                    else:
                        st.error("Generation blocked by safety filters.")
                        status.update(label="Failed", state="error")
                except Exception as e:
                    st.error(f"Error: {e}")

        # === æ¨¡å¼ B: æ–‡æœ¬å¯¹è¯ ===
        else:
            stream_placeholder = st.empty()
            full_resp = ""
            
            try:
                # ç¡®ä¿ Session å­˜åœ¨
                if "gemini_chat" not in st.session_state or not st.session_state.gemini_chat:
                    model = st.session_state.llm_studio.get_chat_model(current_model_id, sys_prompt)
                    st.session_state.gemini_chat = model.start_chat(history=[])
                
                # æµå¼ç”Ÿæˆ
                response_stream = st.session_state.llm_studio.chat_stream(
                    st.session_state.gemini_chat, 
                    last_text, 
                    last_img
                )
                
                for chunk in response_stream:
                    full_resp += chunk
                    stream_placeholder.markdown(full_resp + "â–Œ")
                
                stream_placeholder.markdown(full_resp)
                
                # å­˜å…¥å†å²
                add_message("assistant", full_resp)
                st.rerun() # åˆ·æ–°ä»¥å»é™¤å…‰æ ‡å¹¶æ˜¾ç¤ºåˆ é™¤æŒ‰é’®
                
            except Exception as e:
                st.error(f"Chat Error: {e}")
