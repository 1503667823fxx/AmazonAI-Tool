import streamlit as st
from PIL import Image
import sys
import os
import io

# --- è·¯å¾„ç¯å¢ƒè®¾ç½® ---
current_script_path = os.path.abspath(__file__)
pages_dir = os.path.dirname(current_script_path)
root_dir = os.path.dirname(pages_dir)
if root_dir not in sys.path:
    sys.path.append(root_dir)

try:
    import auth
    from services.llm_engine import LLMEngine
    from services.image_engine import ImageGenEngine
    from app_utils.image_processing import create_preview_thumbnail
    from app_utils.ui_components import show_image_modal
except ImportError as e:
    st.error(f"âŒ æ ¸å¿ƒæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    st.stop()

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="Amazon AI Studio",
    page_icon="ğŸ§ª",
    layout="wide"
)

# --- CSS æ ·å¼ ---
st.markdown("""
<style>
    .block-container { padding-top: 1rem; padding-bottom: 8rem; }
    
    .stChatMessage {
        background-color: transparent;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 0.5rem;
        border: 1px solid rgba(255, 255, 255, 0.1);
    }
    .stChatMessage:hover {
        border-color: rgba(128, 128, 128, 0.3);
        background-color: rgba(240, 242, 246, 0.1);
    }

    /* ç´§å‡‘çš„æ“ä½œæ  */
    .msg-actions {
        display: flex;
        gap: 12px;
        margin-top: 8px;
        opacity: 0.5;
        font-size: 0.85rem;
    }
    .stChatMessage:hover .msg-actions { opacity: 1; }
    
    /* å›¾ç‰‡ç½‘æ ¼ */
    .img-grid {
        display: flex;
        gap: 10px;
        flex-wrap: wrap;
        margin-bottom: 10px;
    }
</style>
""", unsafe_allow_html=True)

# --- 1. åˆå§‹åŒ– ---
if 'auth' in sys.modules and not auth.check_password():
    st.stop()

if "studio_ready" not in st.session_state:
    api_key = st.secrets.get("GOOGLE_API_KEY")
    st.session_state.llm_studio = LLMEngine(api_key)
    st.session_state.img_gen_studio = ImageGenEngine(api_key)
    st.session_state.studio_ready = True

# æ¶ˆæ¯ç»“æ„æ›´æ–°: ref_image -> ref_images (list)
if "studio_msgs" not in st.session_state:
    st.session_state.studio_msgs = []

if "editing_state" not in st.session_state:
    st.session_state.editing_state = None

if "msg_uid" not in st.session_state:
    st.session_state.msg_uid = 0

def get_uid():
    st.session_state.msg_uid += 1
    return st.session_state.msg_uid

# --- 2. è¾…åŠ©å·¥å…· ---

def pil_to_bytes(img, format="JPEG"):
    """
    å°†å›¾ç‰‡è½¬ä¸º Bytesï¼Œå…¼å®¹ PIL Image å’Œ bytes ç±»å‹ã€‚
    ä¿®å¤ï¼šå¦‚æœè¾“å…¥å·²ç»æ˜¯ bytesï¼Œåˆ™ç›´æ¥è¿”å›ï¼Œé¿å… AttributeErrorã€‚
    """
    if isinstance(img, bytes):
        return img
    
    # å¦‚æœæ˜¯ PIL Image å¯¹è±¡ï¼Œåˆ™è¿›è¡Œè½¬æ¢
    buf = io.BytesIO()
    try:
        img.save(buf, format=format, quality=80)
    except Exception:
        # å…œåº•ï¼šå¦‚æœ img æ—¢ä¸æ˜¯ bytes ä¹Ÿä¸æ˜¯ PILï¼Œå¯èƒ½æ˜¯ numpy array ç­‰ï¼Œå°è¯•å¼ºåˆ¶è½¬æ¢
        return None 
    return buf.getvalue()

def delete_msg(idx):
    if 0 <= idx < len(st.session_state.studio_msgs):
        st.session_state.studio_msgs.pop(idx)
        st.rerun()

def start_edit(idx, content):
    st.session_state.editing_state = {"idx": idx, "content": content}
    st.rerun()

def save_edit(idx, new_content):
    st.session_state.studio_msgs[idx]["content"] = new_content
    st.session_state.studio_msgs = st.session_state.studio_msgs[:idx+1]
    st.session_state.editing_state = None
    st.session_state.trigger_inference = True
    st.rerun()

def cancel_edit():
    st.session_state.editing_state = None
    st.rerun()

def regenerate(idx):
    if st.session_state.studio_msgs[idx]["role"] == "model":
        st.session_state.studio_msgs.pop(idx)
        st.session_state.trigger_inference = True
        st.rerun()

def build_gemini_history(msgs):
    """æ„å»º Gemini å†å²ï¼Œæ”¯æŒå¤šå›¾"""
    history = []
    for m in msgs:
        if m["type"] == "text" or m.get("ref_images"):
            parts = []
            # æ·»åŠ å¤šå¼ å›¾ç‰‡
            if m.get("ref_images"):
                parts.extend(m["ref_images"])
            # æ·»åŠ æ–‡æœ¬
            if m["content"]:
                parts.append(m["content"])
            
            if parts:
                history.append({"role": m["role"], "parts": parts})
    return history

# --- 3. ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("ğŸ§ª AI Workbench")
    
    model_map = {
        "âš¡ Gemini Flash (Fast)": "models/gemini-flash-latest",
        "ğŸ§  Gemini 3 Pro (Reasoning)": "models/gemini-3-pro-preview", 
        "ğŸ¨ Gemini 3 Image (Image Gen)": "models/gemini-3-pro-image-preview" 
    }
    
    selected_label = st.selectbox("Model", list(model_map.keys()), label_visibility="collapsed")
    current_model_id = model_map[selected_label]
    is_image_mode = "image-preview" in current_model_id

    st.divider()

    if is_image_mode:
        st.caption("ğŸ¨ Image Config")
        ratio = st.selectbox("Ratio", ["1:1", "4:3", "3:4", "16:9"], index=0)
        seed_val = st.number_input("Seed", value=-1)
    else:
        st.caption("ğŸ§  System Prompt")
        sys_prompt = st.text_area("System Instruction", value="You are a helpful Amazon assistant.", height=150)

    st.divider()
    if st.button("ğŸ—‘ï¸ New Chat", use_container_width=True):
        st.session_state.studio_msgs = []
        st.rerun()

# --- 4. æ¸²æŸ“æ¶ˆæ¯æµ ---
for idx, msg in enumerate(st.session_state.studio_msgs):
    is_editing = (st.session_state.editing_state and st.session_state.editing_state["idx"] == idx)
    
    with st.chat_message(msg["role"]):
        
        # === ç¼–è¾‘æ¨¡å¼ ===
        if is_editing:
            new_val = st.text_area("Edit:", value=msg["content"], height=100)
            c1, c2 = st.columns([1, 6])
            if c1.button("Save", key=f"s_{msg['id']}"): save_edit(idx, new_val)
            if c2.button("Cancel", key=f"c_{msg['id']}"): cancel_edit()
        
        # === æµè§ˆæ¨¡å¼ ===
        else:
            # 1. å¤šå›¾æ˜¾ç¤ºé€»è¾‘ (ç”¨æˆ·ä¸Šä¼ çš„å‚è€ƒå›¾)
            if msg.get("ref_images"):
                cols = st.columns(len(msg["ref_images"]))
                for i, img in enumerate(msg["ref_images"]):
                    with cols[i]:
                        st.image(img, use_container_width=True)
            
            # 2. å†…å®¹æ˜¾ç¤º
            if msg["type"] == "image_result":
                # ç›´æ¥æ˜¾ç¤ºç¼©ç•¥å›¾
                st.image(msg["content"], width=400)
                
                # æ“ä½œåŒº
                act_cols = st.columns([1, 1, 4])
                with act_cols[0]:
                    # ğŸ” ä¼˜åŒ–ç‚¹ï¼šæ”¾å¤§é¢„è§ˆä¸å†è¯·æ±‚ HD Dataï¼Œè€Œæ˜¯ç›´æ¥ç”¨å½“å‰ç¼©ç•¥å›¾è½¬ Bytes
                    # è¿™æ ·å°±æ˜¯ç§’å¼€ï¼Œåªæœ‰æ¨¡ç³Šé¢„è§ˆï¼Œç¬¦åˆæ‚¨çš„è¦æ±‚
                    if st.button("ğŸ” Zoom", key=f"z_{msg['id']}"):
                        preview_bytes = pil_to_bytes(msg["content"]) # å°†ç¼©ç•¥å›¾è½¬ä¸ºäºŒè¿›åˆ¶
                        show_image_modal(preview_bytes, f"Preview-{msg['id']}")
                        
                with act_cols[1]:
                    # ğŸ“¥ åªæœ‰è¿™é‡Œæ‰ä¸‹è½½é«˜æ¸…åŸå›¾
                    st.download_button(
                        "ğŸ“¥", 
                        data=msg["hd_data"], 
                        file_name=f"gen_{msg['id']}.jpg", 
                        mime="image/jpeg", 
                        key=f"dl_{msg['id']}"
                    )
                with act_cols[2]:
                     if st.button("ğŸ—‘ï¸", key=f"del_{msg['id']}"): delete_msg(idx)

            else:
                # æ–‡æœ¬å†…å®¹
                st.markdown(msg["content"])
                
                # æ–‡æœ¬æ“ä½œæ 
                st.markdown('<div class="msg-actions">', unsafe_allow_html=True)
                ac1, ac2, _ = st.columns([2, 1, 6])
                
                with ac1:
                    if msg["role"] == "user":
                        if st.button("âœï¸ Edit", key=f"ed_{msg['id']}"): start_edit(idx, msg["content"])
                    elif msg["role"] == "model":
                        if st.button("ğŸ”„ Regen", key=f"rg_{msg['id']}"): regenerate(idx)
                
                with ac2:
                    if st.button("ğŸ—‘ï¸ Del", key=f"dl_t_{msg['id']}"): delete_msg(idx)
                
                st.markdown('</div>', unsafe_allow_html=True)

st.markdown("<div style='height: 120px;'></div>", unsafe_allow_html=True)

# --- 5. AI æ¨ç†é€»è¾‘ ---
if st.session_state.get("trigger_inference", False):
    st.session_state.trigger_inference = False
    
    if not st.session_state.studio_msgs: st.stop()
    last_msg = st.session_state.studio_msgs[-1]
    
    if last_msg["role"] == "user":
        with st.chat_message("model"):
            
            # A. ç”Ÿå›¾æ¨¡å¼ (Image Gen)
            if is_image_mode:
                with st.status("ğŸ¨ Rendering...", expanded=True):
                    try:
                        # ç”Ÿå›¾é€šå¸¸åªå–ç¬¬ä¸€å¼ å‚è€ƒå›¾ (å¤šå›¾æ§åˆ¶è¾ƒä¸ºå¤æ‚ï¼Œæš‚å–é¦–å¼ )
                        ref_img = last_msg["ref_images"][0] if last_msg.get("ref_images") else None
                        
                        hd_bytes = st.session_state.img_gen_studio.generate(
                            prompt=last_msg["content"],
                            model_name=current_model_id,
                            ref_image=ref_img, 
                            ratio_suffix=f", aspect ratio {ratio.split()[0]}",
                            seed=int(seed_val) if seed_val != -1 else None
                        )
                        if hd_bytes:
                            thumb = create_preview_thumbnail(hd_bytes, 800)
                            st.session_state.studio_msgs.append({
                                "role": "model", "type": "image_result",
                                "content": thumb, "hd_data": hd_bytes, "id": get_uid()
                            })
                            st.rerun()
                        else:
                            st.error("âš ï¸ Filtered / Error")
                    except Exception as e:
                        st.error(f"Error: {e}")

            # B. æ–‡æœ¬/å¯¹è¯æ¨¡å¼ (Text Chat)
            else:
                try:
                    placeholder = st.empty()
                    full_resp = ""
                    
                    # æ„å»ºå†å²
                    past_msgs = st.session_state.studio_msgs[:-1]
                    gemini_history = build_gemini_history(past_msgs)
                    
                    model = st.session_state.llm_studio.get_chat_model(current_model_id, sys_prompt)
                    chat = model.start_chat(history=gemini_history)
                    
                    # æ„å»ºå½“å‰å¤šæ¨¡æ€è¾“å…¥ [text, img1, img2, ...]
                    current_payload = []
                    if last_msg["content"]:
                        current_payload.append(last_msg["content"])
                    if last_msg.get("ref_images"):
                        current_payload.extend(last_msg["ref_images"])
                    
                    # å‘é€è¯·æ±‚
                    response = chat.send_message(current_payload, stream=True)
                    
                    for chunk in response:
                        if chunk.text:
                            full_resp += chunk.text
                            placeholder.markdown(full_resp + "â–Œ")
                    placeholder.markdown(full_resp)
                    
                    st.session_state.studio_msgs.append({
                        "role": "model", "type": "text",
                        "content": full_resp, "id": get_uid()
                    })
                    st.rerun()
                except Exception as e:
                    st.error(f"Error: {e}")

# --- 6. åº•éƒ¨è¾“å…¥åŒº (é›†æˆå¤šæ–‡ä»¶ä¸Šä¼ ) ---
if not st.session_state.get("trigger_inference", False):
    
    bottom_container = st.container()
    
    with bottom_container:
        # ä½¿ç”¨ Popover åŒ…è£…ä¸Šä¼ å™¨ï¼Œå¹¶æ”¹ä¸º accept_multiple_files=True
        with st.popover("ğŸ“ æ·»åŠ é™„ä»¶", use_container_width=False):
            uploaded_files = st.file_uploader(
                "ä¸Šä¼ å›¾ç‰‡ (æ”¯æŒå¤šé€‰)", 
                type=["jpg", "png", "webp"], 
                accept_multiple_files=True, # å…³é”®ä¿®æ”¹
                key="chat_uploader"
            )
            if uploaded_files:
                st.caption(f"âœ… å·²é€‰æ‹© {len(uploaded_files)} å¼ å›¾ç‰‡")

        user_input = st.chat_input("Message...")

    if user_input:
        # å¤„ç†å¤šå›¾
        img_list = []
        if uploaded_files:
            for uf in uploaded_files:
                img_list.append(Image.open(uf))
        
        st.session_state.studio_msgs.append({
            "role": "user",
            "type": "text",
            "content": user_input,
            "ref_images": img_list, # å­˜ä¸ºåˆ—è¡¨
            "id": get_uid()
        })
        st.session_state.trigger_inference = True
        st.rerun()
