import streamlit as st
import replicate
import google.generativeai as genai
from PIL import Image
import io
import sys
import os
import time
from collections import deque 

# --- 0. åŸºç¡€è®¾ç½® ---
sys.path.append(os.path.abspath('.'))
st.set_page_config(page_title="Fashion AI Pro Workflow", page_icon="ğŸ§¬", layout="wide")

# --- 1. é‰´æƒé…ç½® ---
# Replicate
if "REPLICATE_API_TOKEN" in st.secrets:
    os.environ["REPLICATE_API_TOKEN"] = st.secrets["REPLICATE_API_TOKEN"]
else:
    st.error("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° REPLICATE_API_TOKEN")
    st.stop()

# Google
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° GOOGLE_API_KEY")
    st.stop()

# --- 2. å¸¸é‡ä¸æ ·å¼ ---
st.markdown("""
<style>
    .step-header {
        background: linear-gradient(90deg, #f0f2f6 0%, #ffffff 100%);
        padding: 10px 20px;
        border-radius: 8px;
        border-left: 5px solid #4F8BF9;
        margin-top: 20px;
        margin-bottom: 10px;
        font-weight: bold;
        color: #31333F;
    }
    .stButton button {border-radius: 8px;}
    .history-img {border: 2px solid #ddd; border-radius: 5px;}
</style>
""", unsafe_allow_html=True)

# ã€Step 1ã€‘ç”¨çš„è¯»å›¾æ¨¡å‹åˆ—è¡¨ (ä½ æŒ‡å®šçš„)
ANALYSIS_MODELS = [
    "models/gemini-flash-latest",  # æ¨èï¼šæ€§ä»·æ¯”æœ€é«˜çš„ 2.5 ç‰ˆæœ¬
    "models/gemini-2.5-pro",        # å¤‡ç”¨ï¼šç»å…¸å¼ºåŠ›æ¨¡å‹
    "models/gemini-3-pro-preview"       # å¤‡ç”¨ï¼šé¡¶å°–æ¨¡å‹
]

# ã€Step 2ã€‘ç”¨çš„ç”Ÿå›¾æ¨¡å‹åˆ—è¡¨ (ä¹‹å‰æµ‹è¯•é€šè¿‡çš„)
GOOGLE_IMG_MODELS = [
    "models/gemini-2.5-flash-image",
    "models/gemini-3-pro-image-preview"
]

# --- 3. çŠ¶æ€ç®¡ç† ---
if "history_queue" not in st.session_state:
    st.session_state["history_queue"] = deque(maxlen=5)
if "current_step" not in st.session_state:
    st.session_state["current_step"] = 1
if "draft_prompt" not in st.session_state:
    st.session_state["draft_prompt"] = ""
if "google_image_bytes" not in st.session_state:
    st.session_state["google_image_bytes"] = None 
if "flux_prompt" not in st.session_state:
    st.session_state["flux_prompt"] = ""

# --- 4. è¾…åŠ©å‡½æ•° ---
def update_history(image_data, source="AI", prompt_summary=""):
    timestamp = time.strftime("%H:%M:%S")
    st.session_state["history_queue"].appendleft({
        "image": image_data,
        "source": source,
        "time": timestamp,
        "desc": prompt_summary[:20] + "..."
    })

# ==========================================
# ğŸš€ ä¸»ç•Œé¢å¸ƒå±€
# ==========================================

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("ğŸ•’ å†å²è®°å½• (Latest 5)")
    if len(st.session_state["history_queue"]) == 0:
        st.caption("æš‚æ— ç”Ÿæˆè®°å½•")
    else:
        for item in st.session_state["history_queue"]:
            st.markdown(f"**{item['source']}** - {item['time']}")
            if isinstance(item['image'], bytes):
                st.image(item['image'], use_column_width=True)
            else:
                st.image(item['image'], use_column_width=True)
            st.divider()

st.title("ğŸ§¬ Fashion AI å…¨æµç¨‹å·¥ä½œæµ")
st.caption("Flow: ç†è§£ä¸æ„æ€ -> Google åŸå‹ç”Ÿæˆ -> Flux ç²¾ç»†åŒ–é‡ç»˜")

col_main, col_preview = st.columns([1.2, 1], gap="large")

with col_main:
    # ==========================================
    # Step 1: è¾“å…¥ä¸æ„æ€ (The Brain)
    # ==========================================
    st.markdown('<div class="step-header">Step 1: éœ€æ±‚åˆ†æä¸æ„æ€</div>', unsafe_allow_html=True)
    
    # ã€ä¿®æ”¹ç‚¹ 1ã€‘è®©ç”¨æˆ·é€‰æ‹©è¯»å›¾æ¨¡å‹ï¼Œè§£å†³ 404 é—®é¢˜
    analysis_model = st.selectbox(
        "0. é€‰æ‹©è¯»å›¾æ¨¡å‹ (Brain)", 
        ANALYSIS_MODELS, 
        index=0,
        help="å¦‚æœæŠ¥é”™ 404ï¼Œè¯·åˆ‡æ¢å…¶ä»–æ¨¡å‹å°è¯•ã€‚"
    )

    uploaded_file = st.file_uploader("1. ä¸Šä¼ å›¾ç‰‡", type=["jpg", "png", "webp"])
    
    task_type = st.radio(
        "2. é€‰æ‹©ç”Ÿæˆç±»å‹", 
        ["åœºæ™¯å›¾ (Lifestyle)", "å±•ç¤ºå›¾ (Creative)", "äº§å“å›¾ (Product Only)"], 
        horizontal=True,
        help="äº§å“å›¾æ¨¡å¼ä¼šè‡ªåŠ¨å°è¯•å»é™¤æ¨¡ç‰¹ï¼Œå°†è¡£ç‰©/å•†å“å¹³é“ºå±•ç¤ºã€‚"
    )
    
    user_idea = st.text_area("3. ä½ çš„æƒ³æ³• (ç®€å•æè¿°å³å¯)", height=70, placeholder="ä¾‹å¦‚ï¼šåœ¨æµ·è¾¹çš„å¤•é˜³ä¸‹ï¼Œå…‰çº¿æ¸©æš–...")

    if st.button("ğŸ§  ç”Ÿæˆè®¾è®¡æ–¹æ¡ˆ (Draft Prompt)"):
        if not uploaded_file:
            st.warning("è¯·å…ˆä¸Šä¼ å›¾ç‰‡")
        else:
            with st.spinner(f"æ­£åœ¨ä½¿ç”¨ {analysis_model} è¯»å›¾å¹¶è®¾è®¡æ–¹æ¡ˆ..."):
                try:
                    uploaded_file.seek(0)
                    img_obj = Image.open(uploaded_file)
                    
                    # ã€ä¿®æ”¹ç‚¹ 2ã€‘ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹ï¼Œè€Œä¸æ˜¯å†™æ­»çš„ gemini-1.5-flash
                    model = genai.GenerativeModel(analysis_model)
                    
                    special_instruction = ""
                    if "äº§å“å›¾" in task_type:
                        special_instruction = "IMPORTANT: User wants a 'Product Only' shot. Remove any human models, body parts, or mannequins. Lay the clothing/product flat or hang it invisibly. Focus purely on the item itself on a clean background."

                    prompt_req = f"""
                    Role: Expert Commercial Art Director.
                    Task: Analyze the image and user idea to write a perfect prompt for AI Image Generation.
                    
                    Input Image: A fashion product/scene.
                    User Goal: {task_type}
                    User Idea: "{user_idea}"
                    
                    {special_instruction}
                    
                    Requirements:
                    1. Describe the Subject (Product) in detail (keep it faithful).
                    2. Describe the Environment/Background based on User Idea.
                    3. Lighting & Style: Commercial photography, 8k, masterpiece.
                    
                    Output: ONLY the English Prompt text. No explanations.
                    """
                    
                    response = model.generate_content([prompt_req, img_obj])
                    
                    if response.text:
                        st.session_state["draft_prompt"] = response.text.strip()
                        st.session_state["current_step"] = 2
                        st.rerun()
                    else:
                        st.error("æ¨¡å‹è¿”å›äº†ç©ºå†…å®¹ï¼Œè¯·é‡è¯•ã€‚")
                        
                except Exception as e:
                    st.error(f"åˆ†æå¤±è´¥: {e}")
                    st.info("ğŸ’¡ æç¤ºï¼šæŠ¥é”™ 404 è¯´æ˜ä½ é€‰çš„æ¨¡å‹åç§°ä¸å¯¹ï¼Œè¯·åœ¨ä¸Šæ–¹ä¸‹æ‹‰èœå•æ¢ä¸€ä¸ªæ¨¡å‹ã€‚")

    # ==========================================
    # Step 2: Google åŸå‹éªŒè¯ (The Skeleton)
    # ==========================================
    if st.session_state.get("draft_prompt"):
        st.markdown('<div class="step-header">Step 2: Google åŸå‹ç”Ÿæˆ</div>', unsafe_allow_html=True)
        
        edited_prompt = st.text_area("4. ç¡®è®¤/ä¿®æ”¹ æç¤ºè¯æ–¹æ¡ˆ", value=st.session_state["draft_prompt"], height=120)
        st.session_state["draft_prompt"] = edited_prompt 

        # è¿™é‡Œçš„æ¨¡å‹åˆ—è¡¨æ˜¯ä½ ä¹‹å‰æµ‹è¯•é€šè¿‡çš„
        google_model = st.selectbox("5. é€‰æ‹©å¤šæ¨¡æ€ç”Ÿå›¾ AI", GOOGLE_IMG_MODELS)

        if st.button("ğŸ¨ è¿è¡Œ Google ç”Ÿæˆ (åŸå‹éªŒè¯)"):
            with st.spinner(f"æ­£åœ¨è°ƒç”¨ {google_model} ..."):
                try:
                    uploaded_file.seek(0)
                    img_pil = Image.open(uploaded_file)
                    
                    gen_model = genai.GenerativeModel(google_model)
                    
                    # Google å›¾ç”Ÿå›¾é€»è¾‘
                    response = gen_model.generate_content([edited_prompt, img_pil], stream=True)
                    
                    found_img = False
                    for chunk in response:
                        if hasattr(chunk, "parts"):
                            for part in chunk.parts:
                                if part.inline_data:
                                    img_data = part.inline_data.data
                                    st.session_state["google_image_bytes"] = img_data 
                                    found_img = True
                                    update_history(img_data, source="Google", prompt_summary=edited_prompt)
                    
                    if found_img:
                        st.success("Google ç”Ÿæˆå®Œæˆï¼è¯·åœ¨å³ä¾§æŸ¥çœ‹ã€‚")
                        st.session_state["current_step"] = 3
                    else:
                        st.error("Google æœªè¿”å›å›¾ç‰‡ï¼Œå¯èƒ½æ˜¯è¢«å®‰å…¨ç­–ç•¥æ‹¦æˆªæˆ– Prompt è¿è§„ã€‚")
                except Exception as e:
                    st.error(f"Google ç”Ÿæˆå‡ºé”™: {e}")

    # ==========================================
    # Step 3: Flux ç²¾ä¿® (The Final Polish)
    # ==========================================
    if st.session_state.get("google_image_bytes"):
        st.markdown('<div class="step-header">Step 3: Flux è´¨æ„Ÿç²¾ä¿®</div>', unsafe_allow_html=True)
        
        st.info("æ˜¯å¦å¯¹ Google çš„ç»“æœæ»¡æ„ï¼Ÿå¦‚æœä¸æ»¡æ„ï¼Œå¯ä»¥ç”¨ Flux è¿›è¡Œæ›´å¼ºåŠ›çš„é‡ç»˜ã€‚")
        
        flux_feedback = st.text_input("6. (å¯é€‰) å¡«å†™ä¿®æ”¹å»ºè®®", placeholder="ä¾‹å¦‚ï¼šå¢åŠ çš®è‚¤è´¨æ„Ÿï¼Œå…‰çº¿å†æŸ”å’Œä¸€ç‚¹ï¼ŒèƒŒæ™¯è™šåŒ–...")
        
        if st.button("âœ¨ ä¼˜åŒ– Flux æŒ‡ä»¤å¹¶ç”Ÿæˆ"):
            with st.spinner("æ­£åœ¨ä¼˜åŒ–æŒ‡ä»¤å¹¶è°ƒç”¨ Flux Pro..."):
                try:
                    # ã€ä¿®æ”¹ç‚¹ 3ã€‘è¿™é‡Œä¹Ÿä½¿ç”¨ Step 1 é€‰ä¸­çš„æ¨¡å‹æ¥åšæ–‡æœ¬ä¼˜åŒ–ï¼Œä¿è¯ä¸€è‡´æ€§
                    optimizer_model = genai.GenerativeModel(analysis_model)
                    
                    opt_req = f"""
                    Base Prompt: {st.session_state["draft_prompt"]}
                    User Feedback: {flux_feedback}
                    
                    Task: Rewrite the Base Prompt to incorporate User Feedback. 
                    Ensure keywords for Flux model are added: "hyper-realistic, 8k, film grain, ray tracing".
                    Output: ONLY the optimized English Prompt.
                    """
                    opt_res = optimizer_model.generate_content(opt_req)
                    final_flux_prompt = opt_res.text.strip()
                    st.session_state["flux_prompt"] = final_flux_prompt 
                    
                    uploaded_file.seek(0)
                    
                    output = replicate.run(
                        "black-forest-labs/flux-dev",
                        input={
                            "prompt": final_flux_prompt,
                            "image": uploaded_file, 
                            "prompt_strength": 0.75, 
                            "go_fast": True,
                            "num_outputs": 1,
                            "output_format": "jpg",
                            "output_quality": 100,
                            "negative_prompt": "blurry, low quality, illustration, painting, cartoon"
                        }
                    )
                    
                    flux_url = str(output[0]) if isinstance(output, list) else str(output)
                    
                    update_history(flux_url, source="Flux", prompt_summary=final_flux_prompt)
                    st.success("Flux ç²¾ä¿®å®Œæˆï¼")
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"Flux å¤„ç†å¤±è´¥: {e}")

# ==========================================
# å³ä¾§é¢„è§ˆåŒº
# ==========================================
with col_preview:
    st.header("ğŸ–¼ï¸ å®æ—¶ç”»å¸ƒ")
    
    if st.session_state.get("google_image_bytes"):
        st.subheader("Google Prototype")
        g_img = Image.open(io.BytesIO(st.session_state["google_image_bytes"]))
        st.image(g_img, caption="Google Result", use_column_width=True)
        st.download_button("ğŸ“¥ ä¸‹è½½ Google å›¾", st.session_state["google_image_bytes"], file_name="google_draft.png")
    
    latest_flux = None
    for item in st.session_state["history_queue"]:
        if item["source"] == "Flux":
            latest_flux = item
            break
            
    if latest_flux:
        st.divider()
        st.subheader("Flux Final Result")
        st.image(latest_flux["image"], caption="Flux Result", use_column_width=True)
        st.info(f"ä½¿ç”¨çš„ Prompt: {latest_flux.get('desc', '')}")
    
    if not st.session_state.get("google_image_bytes") and not latest_flux:
        st.info("ç­‰å¾…æ“ä½œ... è¯·åœ¨å·¦ä¾§ä¸Šä¼ å›¾ç‰‡å¹¶å¼€å§‹ã€‚")
        if uploaded_file:
            st.image(uploaded_file, caption="åŸå§‹å›¾ç‰‡", width=200)
        for i, url in enumerate(st.session_state["generated_image_urls"]):
            st.image(url, caption=f"Result {i+1}", use_column_width=True)
            st.markdown(f"[ğŸ“¥ ç‚¹å‡»ä¸‹è½½å¤§å›¾]({url})")
