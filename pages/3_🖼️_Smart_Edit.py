import streamlit as st
import replicate
import google.generativeai as genai
from PIL import Image
import io
import sys
import os
import time
from collections import deque # ç”¨äºå®ç°å®šé•¿å†å²è®°å½•

# --- 0. åŸºç¡€è®¾ç½® ---
sys.path.append(os.path.abspath('.'))
st.set_page_config(page_title="Fashion AI Pro Workflow", page_icon="ğŸ§¬", layout="wide")

# --- 1. é‰´æƒé…ç½® ---
# Replicate
if "REPLICATE_API_TOKEN" in st.secrets:
    os.environ["REPLICATE_API_TOKEN"] = st.secrets["REPLICATE_API_TOKEN"]
else:
    st.error("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° REPLICATE_API_TOKEN")
    st.stop()

# Google
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° GOOGLE_API_KEY")
    st.stop()

# --- 2. å¸¸é‡ä¸æ ·å¼ ---
st.markdown("""
<style>
    .step-header {
        background: linear-gradient(90deg, #f0f2f6 0%, #ffffff 100%);
        padding: 10px 20px;
        border-radius: 8px;
        border-left: 5px solid #4F8BF9;
        margin-top: 20px;
        margin-bottom: 10px;
        font-weight: bold;
        color: #31333F;
    }
    .stButton button {border-radius: 8px;}
    .history-img {border: 2px solid #ddd; border-radius: 5px;}
</style>
""", unsafe_allow_html=True)

# Google ç”Ÿå›¾æ¨¡å‹åˆ—è¡¨ (é”å®šè¿™ä¸¤ä¸ªæœ€å¼ºçš„)
GOOGLE_IMG_MODELS = [
    "models/gemini-2.5-flash-image",
    "models/gemini-3-pro-image-preview"
]

# --- 3. çŠ¶æ€ç®¡ç† (Session State) ---
if "history_queue" not in st.session_state:
    st.session_state["history_queue"] = deque(maxlen=5) # è‡ªåŠ¨ä¿ç•™æœ€å5ä¸ª
if "current_step" not in st.session_state:
    st.session_state["current_step"] = 1
if "draft_prompt" not in st.session_state:
    st.session_state["draft_prompt"] = ""
if "google_image_bytes" not in st.session_state:
    st.session_state["google_image_bytes"] = None # å­˜å‚¨ Google ç”Ÿæˆå›¾çš„äºŒè¿›åˆ¶
if "flux_prompt" not in st.session_state:
    st.session_state["flux_prompt"] = ""

# --- 4. è¾…åŠ©å‡½æ•° ---
def update_history(image_data, source="AI", prompt_summary=""):
    """æ›´æ–°å†å²è®°å½•"""
    timestamp = time.strftime("%H:%M:%S")
    st.session_state["history_queue"].appendleft({
        "image": image_data,
        "source": source,
        "time": timestamp,
        "desc": prompt_summary[:20] + "..."
    })

def get_text_model():
    return genai.GenerativeModel('gemini-1.5-flash')

# ==========================================
# ğŸš€ ä¸»ç•Œé¢å¸ƒå±€
# ==========================================

# ä¾§è¾¹æ ï¼šå†å²è®°å½•
with st.sidebar:
    st.header("ğŸ•’ å†å²è®°å½• (Latest 5)")
    if len(st.session_state["history_queue"]) == 0:
        st.caption("æš‚æ— ç”Ÿæˆè®°å½•")
    else:
        for item in st.session_state["history_queue"]:
            st.markdown(f"**{item['source']}** - {item['time']}")
            # åˆ¤æ–­æ˜¯ URL è¿˜æ˜¯ Bytes
            if isinstance(item['image'], bytes):
                st.image(item['image'], use_column_width=True)
            else:
                st.image(item['image'], use_column_width=True)
            st.divider()

st.title("ğŸ§¬ Fashion AI å…¨æµç¨‹å·¥ä½œæµ")
st.caption("Flow: ç†è§£ä¸æ„æ€ -> Google åŸå‹ç”Ÿæˆ -> Flux ç²¾ç»†åŒ–é‡ç»˜")

# åˆ†æ å¸ƒå±€
col_main, col_preview = st.columns([1.2, 1], gap="large")

with col_main:
    # ==========================================
    # Step 1: è¾“å…¥ä¸æ„æ€ (The Brain)
    # ==========================================
    st.markdown('<div class="step-header">Step 1: éœ€æ±‚åˆ†æä¸æ„æ€</div>', unsafe_allow_html=True)
    
    uploaded_file = st.file_uploader("1. ä¸Šä¼ å›¾ç‰‡", type=["jpg", "png", "webp"])
    
    task_type = st.radio(
        "2. é€‰æ‹©ç”Ÿæˆç±»å‹", 
        ["åœºæ™¯å›¾ (Lifestyle)", "å±•ç¤ºå›¾ (Creative)", "äº§å“å›¾ (Product Only)"], 
        horizontal=True,
        help="äº§å“å›¾æ¨¡å¼ä¼šè‡ªåŠ¨å°è¯•å»é™¤æ¨¡ç‰¹ï¼Œå°†è¡£ç‰©/å•†å“å¹³é“ºå±•ç¤ºã€‚"
    )
    
    user_idea = st.text_area("3. ä½ çš„æƒ³æ³• (ç®€å•æè¿°å³å¯)", height=70, placeholder="ä¾‹å¦‚ï¼šåœ¨æµ·è¾¹çš„å¤•é˜³ä¸‹ï¼Œå…‰çº¿æ¸©æš–...")

    if st.button("ğŸ§  ç”Ÿæˆè®¾è®¡æ–¹æ¡ˆ (Draft Prompt)"):
        if not uploaded_file:
            st.warning("è¯·å…ˆä¸Šä¼ å›¾ç‰‡")
        else:
            with st.spinner("Gemini æ­£åœ¨è¯»å›¾å¹¶è®¾è®¡æ–¹æ¡ˆ..."):
                try:
                    uploaded_file.seek(0)
                    img_obj = Image.open(uploaded_file)
                    model = get_text_model()
                    
                    # é’ˆå¯¹â€œäº§å“å›¾â€çš„ç‰¹æ®Šé€»è¾‘
                    special_instruction = ""
                    if "äº§å“å›¾" in task_type:
                        special_instruction = "IMPORTANT: User wants a 'Product Only' shot. Remove any human models, body parts, or mannequins. Lay the clothing/product flat or hang it invisibly. Focus purely on the item itself on a clean background."

                    prompt_req = f"""
                    Role: Expert Commercial Art Director.
                    Task: Analyze the image and user idea to write a perfect prompt for AI Image Generation.
                    
                    Input Image: A fashion product/scene.
                    User Goal: {task_type}
                    User Idea: "{user_idea}"
                    
                    {special_instruction}
                    
                    Requirements:
                    1. Describe the Subject (Product) in detail (keep it faithful).
                    2. Describe the Environment/Background based on User Idea.
                    3. Lighting & Style: Commercial photography, 8k, masterpiece.
                    
                    Output: ONLY the English Prompt text. No explanations.
                    """
                    
                    response = model.generate_content([prompt_req, img_obj])
                    st.session_state["draft_prompt"] = response.text.strip()
                    st.session_state["current_step"] = 2
                    st.rerun() # åˆ·æ–°è¿›å…¥ä¸‹ä¸€æ­¥
                except Exception as e:
                    st.error(f"åˆ†æå¤±è´¥: {e}")

    # ==========================================
    # Step 2: Google åŸå‹éªŒè¯ (The Skeleton)
    # ==========================================
    if st.session_state.get("draft_prompt"):
        st.markdown('<div class="step-header">Step 2: Google åŸå‹ç”Ÿæˆ</div>', unsafe_allow_html=True)
        
        # 4. ç”¨æˆ·ç¼–è¾‘ Prompt
        edited_prompt = st.text_area("4. ç¡®è®¤/ä¿®æ”¹ æç¤ºè¯æ–¹æ¡ˆ", value=st.session_state["draft_prompt"], height=120)
        st.session_state["draft_prompt"] = edited_prompt # åŒæ­¥ä¿®æ”¹

        # 5. é€‰æ‹© Google æ¨¡å‹
        google_model = st.selectbox("5. é€‰æ‹©å¤šæ¨¡æ€ AI", GOOGLE_IMG_MODELS)

        if st.button("ğŸ¨ è¿è¡Œ Google ç”Ÿæˆ (åŸå‹éªŒè¯)"):
            with st.spinner(f"æ­£åœ¨è°ƒç”¨ {google_model} ..."):
                try:
                    uploaded_file.seek(0)
                    img_pil = Image.open(uploaded_file)
                    
                    gen_model = genai.GenerativeModel(google_model)
                    
                    # Google å›¾ç”Ÿå›¾é€»è¾‘
                    response = gen_model.generate_content([edited_prompt, img_pil], stream=True)
                    
                    found_img = False
                    for chunk in response:
                        if hasattr(chunk, "parts"):
                            for part in chunk.parts:
                                if part.inline_data:
                                    img_data = part.inline_data.data
                                    st.session_state["google_image_bytes"] = img_data # å­˜å…¥ç¼“å­˜
                                    found_img = True
                                    # æ›´æ–°å†å²
                                    update_history(img_data, source="Google", prompt_summary=edited_prompt)
                    
                    if found_img:
                        st.success("Google ç”Ÿæˆå®Œæˆï¼è¯·åœ¨å³ä¾§æŸ¥çœ‹ã€‚")
                        st.session_state["current_step"] = 3
                    else:
                        st.error("Google æœªè¿”å›å›¾ç‰‡ï¼Œå¯èƒ½æ˜¯è¢«å®‰å…¨ç­–ç•¥æ‹¦æˆªæˆ– Prompt è¿è§„ã€‚")
                except Exception as e:
                    st.error(f"Google ç”Ÿæˆå‡ºé”™: {e}")

    # ==========================================
    # Step 3: Flux ç²¾ä¿® (The Final Polish)
    # ==========================================
    if st.session_state.get("google_image_bytes"):
        st.markdown('<div class="step-header">Step 3: Flux è´¨æ„Ÿç²¾ä¿®</div>', unsafe_allow_html=True)
        
        st.info("æ˜¯å¦å¯¹ Google çš„ç»“æœæ»¡æ„ï¼Ÿå¦‚æœä¸æ»¡æ„ï¼Œå¯ä»¥ç”¨ Flux è¿›è¡Œæ›´å¼ºåŠ›çš„é‡ç»˜ã€‚")
        
        # 7. ç”¨æˆ·å¡«å†™ä¿®æ”¹å»ºè®®
        flux_feedback = st.text_input("6. (å¯é€‰) å¡«å†™ä¿®æ”¹å»ºè®®", placeholder="ä¾‹å¦‚ï¼šå¢åŠ çš®è‚¤è´¨æ„Ÿï¼Œå…‰çº¿å†æŸ”å’Œä¸€ç‚¹ï¼ŒèƒŒæ™¯è™šåŒ–...")
        
        # 8. AI æ¶¦è‰² Flux æŒ‡ä»¤
        if st.button("âœ¨ ä¼˜åŒ– Flux æŒ‡ä»¤å¹¶ç”Ÿæˆ"):
            with st.spinner("æ­£åœ¨ä¼˜åŒ–æŒ‡ä»¤å¹¶è°ƒç”¨ Flux Pro..."):
                try:
                    # A. ä¼˜åŒ– Prompt
                    optimizer_model = get_text_model()
                    opt_req = f"""
                    Base Prompt: {st.session_state["draft_prompt"]}
                    User Feedback: {flux_feedback}
                    
                    Task: Rewrite the Base Prompt to incorporate User Feedback. 
                    Ensure keywords for Flux model are added: "hyper-realistic, 8k, film grain, ray tracing".
                    Output: ONLY the optimized English Prompt.
                    """
                    opt_res = optimizer_model.generate_content(opt_req)
                    final_flux_prompt = opt_res.text.strip()
                    st.session_state["flux_prompt"] = final_flux_prompt # è®°å½•
                    
                    # B. è°ƒç”¨ Flux
                    # å†³ç­–ï¼šFlux ç”¨åŸå›¾è¿˜æ˜¯ç”¨ Google å›¾ï¼Ÿ
                    # é€»è¾‘ï¼šé€šå¸¸ä¸ºäº†ä¿ç•™äº§å“ç»†èŠ‚ï¼Œç”¨åŸå›¾ + æ–° Prompt æ•ˆæœæ›´å¥½ã€‚
                    # å¦‚æœæƒ³è¦å®Œå…¨åˆ©ç”¨ Google çš„æ„å›¾ï¼Œå¯ä»¥ç”¨ Google å›¾ï¼Œä½†åœ¨â€œäº§å“å›¾â€åœºæ™¯ä¸‹ï¼ŒåŸå›¾ç»†èŠ‚æœ€é‡è¦ã€‚
                    # è¿™é‡Œé»˜è®¤ä½¿ç”¨ã€åŸå›¾ã€‘ä½œä¸ºåº•å›¾ï¼Œåˆ©ç”¨ Google éªŒè¯è¿‡çš„ Promptã€‚
                    uploaded_file.seek(0)
                    
                    output = replicate.run(
                        "black-forest-labs/flux-dev",
                        input={
                            "prompt": final_flux_prompt,
                            "image": uploaded_file, # ä½¿ç”¨åŸå›¾ä»¥ä¿çœŸ
                            "prompt_strength": 0.75, # é€‚åˆé‡ç»˜
                            "go_fast": True,
                            "num_outputs": 1,
                            "output_format": "jpg",
                            "output_quality": 100,
                            "negative_prompt": "blurry, low quality, illustration, painting, cartoon"
                        }
                    )
                    
                    # å¤„ç† Flux ç»“æœ
                    flux_url = str(output[0]) if isinstance(output, list) else str(output)
                    
                    # æ›´æ–°å†å²
                    update_history(flux_url, source="Flux", prompt_summary=final_flux_prompt)
                    st.success("Flux ç²¾ä¿®å®Œæˆï¼")
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"Flux å¤„ç†å¤±è´¥: {e}")

# ==========================================
# å³ä¾§é¢„è§ˆåŒº
# ==========================================
with col_preview:
    st.header("ğŸ–¼ï¸ å®æ—¶ç”»å¸ƒ")
    
    # 1. æ˜¾ç¤º Google ç»“æœ
    if st.session_state.get("google_image_bytes"):
        st.subheader("Google Prototype")
        g_img = Image.open(io.BytesIO(st.session_state["google_image_bytes"]))
        st.image(g_img, caption="Google 2.5/3.0 Result", use_column_width=True)
        
        # ä¸‹è½½æŒ‰é’®
        st.download_button("ğŸ“¥ ä¸‹è½½ Google å›¾", st.session_state["google_image_bytes"], file_name="google_draft.png")
    
    # 2. æ˜¾ç¤º Flux ç»“æœ (å¦‚æœæœ‰)
    # è·å–å†å²è®°å½•ä¸­æœ€æ–°çš„ Flux å›¾ç‰‡
    latest_flux = None
    for item in st.session_state["history_queue"]:
        if item["source"] == "Flux":
            latest_flux = item
            break
            
    if latest_flux:
        st.divider()
        st.subheader("Flux Final Result")
        st.image(latest_flux["image"], caption="Flux Refined Result", use_column_width=True)
        st.info(f"ä½¿ç”¨çš„ Prompt: {latest_flux.get('desc', '')}")
    
    # 3. å¦‚æœè¿˜æ²¡ç”Ÿæˆï¼Œæ˜¾ç¤ºå ä½
    if not st.session_state.get("google_image_bytes") and not latest_flux:
        st.info("ç­‰å¾…æ“ä½œ... è¯·åœ¨å·¦ä¾§ä¸Šä¼ å›¾ç‰‡å¹¶å¼€å§‹ã€‚")
        if uploaded_file:
            st.image(uploaded_file, caption="åŸå§‹å›¾ç‰‡", width=200)
        st.subheader("ğŸ‘€ ç”Ÿæˆç»“æœ")
        for i, url in enumerate(st.session_state["generated_image_urls"]):
            st.image(url, caption=f"Result {i+1}", use_column_width=True)
            st.markdown(f"[ğŸ“¥ ç‚¹å‡»ä¸‹è½½å¤§å›¾]({url})")
