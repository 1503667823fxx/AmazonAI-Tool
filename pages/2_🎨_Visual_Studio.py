import streamlit as st
import replicate
import google.generativeai as genai
from PIL import Image, ImageOps, UnidentifiedImageError
import io
import sys
import os
import requests
import time
import base64 
import json

# --- 0. å¼•å…¥é—¨ç¦ç³»ç»Ÿ ---
sys.path.append(os.path.abspath('.'))
try:
    import auth
except ImportError:
    pass 

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="è§†è§‰å·¥åœº", page_icon="ğŸ¨", layout="wide")

# å®‰å…¨æ£€æŸ¥
if 'auth' in sys.modules:
    if not auth.check_password():
        st.stop()

# --- è‡ªå®šä¹‰ CSS ---
st.markdown("""
<style>
    .stButton button {width: 100%; border-radius: 8px;}
    .stImage {border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);}
    /* ä¼˜åŒ– Tab æ ·å¼ */
    .stTabs [data-baseweb="tab-list"] {gap: 10px;}
    .stTabs [data-baseweb="tab"] {
        height: 50px; 
        background-color: #f8f9fa; 
        border-radius: 5px 5px 0 0;
        border: 1px solid #e0e0e0;
        border-bottom: none;
    }
    .stTabs [aria-selected="true"] {
        background-color: #ffffff; 
        border-top: 3px solid #ff9900;
        font-weight: bold;
    }
    .stTextArea textarea {font-family: 'Consolas', monospace; font-size: 14px;}
</style>
""", unsafe_allow_html=True)

# --- 2. éªŒè¯ Keys ---
if "REPLICATE_API_TOKEN" not in st.secrets:
    st.error("âŒ æœªæ‰¾åˆ° Replicate API Token")
    st.stop()
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])

# --- 3. åº•å±‚å¸¸é‡ ---
UNIVERSAL_QUALITY_PROMPT = ", commercial photography, 8k resolution, photorealistic, highly detailed, cinematic lighting, depth of field, masterpiece, sharp focus"

# --- 4. è¾…åŠ©å‡½æ•° ---
def download_image(url_or_data, filename, is_bytes=False):
    """æä¾›ä¸‹è½½é“¾æ¥ (æ”¯æŒ URL å’Œ Bytes)"""
    if is_bytes:
        b64 = base64.b64encode(url_or_data).decode()
        href = f'<a href="data:image/jpeg;base64,{b64}" download="{filename}">ğŸ“¥ ç‚¹å‡»ä¸‹è½½ {filename}</a>'
        st.markdown(href, unsafe_allow_html=True)
    else:
        st.markdown(f"### [ğŸ“¥ ç‚¹å‡»ä¸‹è½½ {filename}]({url_or_data})")

def get_pro_vision_model():
    """è·å–é«˜çº§è§†è§‰æ¨¡å‹ (ç”¨äºè¯»å›¾å†™æŒ‡ä»¤ï¼Œä¸ç”Ÿå›¾)"""
    return genai.GenerativeModel('gemini-3-pro-preview') 

def get_image_gen_model_v3():
    """è·å–å›¾åƒç”Ÿæˆæ¨¡å‹ V3 (ä¼˜å…ˆ)"""
    return genai.GenerativeModel('gemini-3-pro-image-preview')

def get_image_gen_model_v25():
    """è·å–å›¾åƒç”Ÿæˆæ¨¡å‹ V2.5 (ä¿åº•)"""
    return genai.GenerativeModel('gemini-2.5-flash-image-preview')

def validate_and_process_image(response_obj, model_name):
    """
    ã€ç»ˆæè¯Šæ–­ç‰ˆã€‘è§£æ Gemini å“åº”ï¼Œå¢åŠ è¯¦ç»† Debug ä¿¡æ¯
    """
    try:
        # 0. æ£€æŸ¥ Prompt Feedback
        if response_obj.prompt_feedback:
            if response_obj.prompt_feedback.block_reason:
                return None, f"ğŸš« {model_name} è¯·æ±‚è¢«æ‹¦æˆª (Blocked)ï¼ŒåŸå› : {response_obj.prompt_feedback.block_reason}"

        # 1. æ£€æŸ¥ Candidates
        if not response_obj.candidates:
            return None, f"âš ï¸ {model_name} æœªè¿”å›ä»»ä½• Candidateã€‚å¯èƒ½æœåŠ¡å™¨ç¹å¿™æˆ– Prompt è¢«å®Œå…¨è¿‡æ»¤ã€‚"

        candidate = response_obj.candidates[0]
        
        # 2. æ£€æŸ¥ Finish Reason
        finish_reason_map = {1: "STOP (æ­£å¸¸)", 2: "MAX_TOKENS", 3: "SAFETY (å®‰å…¨æ‹¦æˆª)", 4: "RECITATION", 5: "OTHER"}
        finish_code = candidate.finish_reason
        finish_str = finish_reason_map.get(finish_code, str(finish_code))
        
        if finish_code == 3:
            return None, f"ğŸ›¡ï¸ {model_name} è§¦å‘å®‰å…¨æ‹¦æˆª (SAFETY)ã€‚è¯·ä¿®æ”¹æŒ‡ä»¤ã€‚"

        # 3. éå† Parts å¯»æ‰¾å›¾ç‰‡
        if not candidate.content.parts:
            return None, f"âš ï¸ {model_name} è¿”å›å†…å®¹ä¸ºç©º (Finish Reason: {finish_str})ã€‚è¿™é€šå¸¸æ„å‘³ç€æ¨¡å‹ä¸çŸ¥é“å¦‚ä½•å¤„ç†è¾“å…¥ã€‚"

        image_bytes = None
        text_feedback = []

        for i, part in enumerate(candidate.content.parts):
            # ä¼˜å…ˆæ‰¾å›¾ç‰‡
            if part.inline_data and part.inline_data.data:
                try:
                    decoded = base64.b64decode(part.inline_data.data)
                    Image.open(io.BytesIO(decoded)).verify()
                    image_bytes = decoded
                    break 
                except Exception as e:
                    print(f"Part {i} å›¾ç‰‡æ ¡éªŒå¤±è´¥: {e}")
                    continue
            
            if part.text:
                text_feedback.append(part.text)

        # 4. æœ€ç»ˆåˆ¤å®š
        if image_bytes:
            return image_bytes, None
        
        # é”™è¯¯ç»„è£…
        error_msg = f"âŒ {model_name} æœªç”Ÿæˆæœ‰æ•ˆå›¾ç‰‡ã€‚"
        if text_feedback:
            error_msg += f"\nğŸ¤– AI å›å¤äº†æ–‡æœ¬: {' '.join(text_feedback)}"
        else:
            error_msg += f"\n(è°ƒè¯•ä¿¡æ¯: Finish Reason={finish_str}, Parts Count={len(candidate.content.parts)})"
            
        return None, error_msg

    except Exception as e:
        return None, f"ğŸ’¥ ç³»ç»Ÿè§£æé”™è¯¯: {str(e)}"

# --- 5. é¡¶éƒ¨å¯¼èˆª ---
st.title("ğŸ¨ äºšé©¬é€Š AI è§†è§‰å·¥åœº (Pro)")
st.caption("é›†æˆ FLUX.1 Pro, Gemini 3.0 Pro, FaceSwap ç­‰é¡¶çº§æ¨¡å‹")

# åˆå§‹åŒ– Session State
if "t2i_final_prompt" not in st.session_state:
    st.session_state["t2i_final_prompt"] = ""
if "scene_gen_prompt" not in st.session_state:
    st.session_state["scene_gen_prompt"] = ""
if "step1_image" not in st.session_state:
    st.session_state["step1_image"] = None
if "hybrid_instruction" not in st.session_state:
    st.session_state["hybrid_instruction"] = ""
if "hybrid_recommendations" not in st.session_state:
    st.session_state["hybrid_recommendations"] = None

# åˆ›å»ºåŠŸèƒ½åˆ†åŒº
tabs = st.tabs([
    "ğŸ–¼ï¸ åŒæ¨¡å›¾ç”Ÿå›¾ (æ··åˆ)", 
    "âœ¨ æ–‡ç”Ÿå›¾ (æµ·æŠ¥)", 
    "ğŸ–Œï¸ å±€éƒ¨é‡ç»˜", 
    "â†”ï¸ ç”»å¹…æ‰©å±•", 
    "ğŸ” é«˜æ¸…æ”¾å¤§", 
    "ğŸ§© A+ åŠ©æ‰‹"
])

# ==================================================
# Tab 1: åŒæ¨¡å›¾ç”Ÿå›¾ (Gemini -> Flux)
# ==================================================
with tabs[0]:
    st.header("ğŸ–¼ï¸ åŒæ¨¡æ··åˆå›¾ç”Ÿå›¾ (Hybrid Workflow)")
    
    col1, col2 = st.columns([5, 5])
    
    # === å·¦ä¾§ï¼šè¾“å…¥ä¸æ„æ€ ===
    with col1:
        st.subheader("1. æ„æ€ä¸æŒ‡ä»¤ (Brain)")
        ref_img = st.file_uploader("ä¸Šä¼ åŸå›¾", type=["jpg", "png", "webp"], key="hybrid_up")
        
        if ref_img:
            st.image(ref_img, width=200, caption="åŸå›¾")
            
            st.markdown("#### ç¬¬ä¸€æ­¥ï¼šå‘Šè¯‰ AI ä½ æƒ³è¦ä»€ä¹ˆ")
            
            task_type = st.radio(
                "ç”Ÿæˆæ–¹å‘ï¼š", 
                ["ğŸ¡ åœºæ™¯å›¾ (Lifestyle)", "âœ¨ å±•ç¤ºå›¾ (Creative)", "ğŸ” äº§å“å›¾ (Focus)"], 
                horizontal=True
            )
            
            user_idea = st.text_area(
                "æ‚¨çš„å…·ä½“æƒ³æ³• (ä¸­æ–‡/è‹±æ–‡)", 
                height=80, 
                placeholder="ä¾‹å¦‚ï¼šæˆ‘æƒ³è¦ä¸€ä¸ªæ¸©é¦¨çš„åœ£è¯èŠ‚æ°›å›´..."
            )
            
            if st.button("ğŸ§  Gemini è¯»å›¾å¹¶ç”ŸæˆæŒ‡ä»¤", type="secondary"):
                with st.spinner("Gemini 3.0 Pro æ­£åœ¨åˆ†æ..."):
                    try:
                        img_obj = Image.open(ref_img)
                        model = get_pro_vision_model()
                        
                        prompt = f"""
                        ä½ æ˜¯ä¸€ä¸ªäºšé©¬é€Šç”µå•†è§†è§‰ä¸“å®¶ã€‚è¯·åŸºäºè¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼Œç»“åˆç”¨æˆ·çš„éœ€æ±‚ï¼Œå†™ä¸€æ®µç”¨äº AI å›¾åƒç¼–è¾‘çš„ç²¾ç¡®æŒ‡ä»¤ (Prompt)ã€‚
                        
                        ã€ä»»åŠ¡ç±»å‹ã€‘{task_type}
                        ã€ç”¨æˆ·æƒ³æ³•ã€‘{user_idea}
                        
                        ã€è¾“å‡ºè¦æ±‚ã€‘
                        è¯·è¾“å‡ºä¸€æ®µ **è‹±æ–‡** æŒ‡ä»¤ï¼Œæ ¼å¼ä¸ºï¼š
                        "Create an image of [product description] with [background description]. Lighting should be [lighting description]."
                        æ³¨æ„ï¼šè¯·ä½¿ç”¨"Create an image of..."è€Œä¸æ˜¯"Edit this image..."ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½ç”Ÿæˆæ–°å›¾ã€‚
                        """
                        
                        response = model.generate_content([prompt, img_obj])
                        st.session_state["hybrid_instruction"] = response.text
                        st.success("âœ… æŒ‡ä»¤å·²ç”Ÿæˆï¼")
                        st.rerun()
                    except Exception as e:
                        st.error(f"åˆ†æå¤±è´¥: {e}")

            # 4. ç¡®è®¤æŒ‡ä»¤
            st.markdown("#### ç¬¬äºŒæ­¥ï¼šç¡®è®¤æŒ‡ä»¤")
            edit_instruction = st.text_area(
                "æœ€ç»ˆç¼–è¾‘æŒ‡ä»¤ (è‹±æ–‡ - Step 1 ç”¨)", 
                value=st.session_state["hybrid_instruction"], 
                height=120
            )
            
            # 5. æ‰§è¡Œ Step 1
            st.markdown("#### ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆè‰å›¾")
            if st.button("âœ¨ Step 1: Gemini ç”Ÿæˆè‰å›¾", type="primary"):
                if not ref_img or not edit_instruction:
                    st.warning("è¯·å…ˆç”ŸæˆæŒ‡ä»¤ï¼")
                else:
                    st.session_state["step1_image"] = None 
                    
                    with st.spinner("ğŸ§  æ­£åœ¨ç»˜åˆ¶è‰å›¾..."):
                        try:
                            # å‡†å¤‡å›¾ç‰‡
                            ref_img.seek(0)
                            original_img = Image.open(ref_img).convert("RGB")
                            original_img.thumbnail((1024, 1024)) 
                            
                            # --- å°è¯• A: 3.0 Pro (å¸¦å›¾) ---
                            model_v3 = get_image_gen_model_v3()
                            success = False
                            error_report = ""
                            
                            try:
                                # å°è¯• Img2Img (å¦‚æœæ”¯æŒ)
                                response = model_v3.generate_content(
                                    [edit_instruction, original_img],
                                    generation_config={"response_modalities": ["IMAGE"]}
                                )
                                img_bytes, err_msg = validate_and_process_image(response, "Gemini 3.0 Pro (Img2Img)")
                                
                                if img_bytes:
                                    st.session_state["step1_image"] = img_bytes
                                    st.success("âœ… 3.0 Pro ç”ŸæˆæˆåŠŸï¼")
                                    success = True
                                else:
                                    error_report = err_msg
                                    print(f"V3 Img2Img å¤±è´¥: {err_msg}")
                                    
                            except Exception as e:
                                error_report = str(e)
                                print(f"V3 Img2Img å¼‚å¸¸: {e}")
                            
                            # --- å°è¯• B: 3.0 Pro (ä¸å¸¦å›¾ - Text-to-Image) ---
                            # å¦‚æœå¸¦å›¾å¤±è´¥ï¼Œè¯´æ˜æ¨¡å‹å¯èƒ½ä¸æ”¯æŒ Image Input for Generationï¼Œå°è¯•çº¯æ–‡ç”Ÿå›¾
                            if not success:
                                st.warning(f"3.0 Pro å›¾ç”Ÿå›¾æ¨¡å¼æœªæˆåŠŸ ({error_report})ï¼Œå°è¯•çº¯æ–‡æœ¬ç”Ÿæˆæ¨¡å¼...")
                                
                                try:
                                    response_txt = model_v3.generate_content(
                                        [edit_instruction], # åªä¼ æ–‡æœ¬
                                        generation_config={"response_modalities": ["IMAGE"]}
                                    )
                                    img_bytes, err_msg = validate_and_process_image(response_txt, "Gemini 3.0 Pro (Text2Img)")
                                    
                                    if img_bytes:
                                        st.session_state["step1_image"] = img_bytes
                                        st.success("âœ… 3.0 Pro (çº¯æ–‡æœ¬æ¨¡å¼) ç”ŸæˆæˆåŠŸï¼")
                                        success = True
                                    else:
                                        error_report = err_msg
                                except Exception as e:
                                    error_report = str(e)

                            # --- å°è¯• C: 2.5 Flash (ä¿åº•) ---
                            if not success:
                                st.warning(f"3.0 Pro å…¨é¢å¤±è´¥ï¼Œåˆ‡æ¢è‡³ 2.5 Flash Image é‡è¯•...")
                                model_v25 = get_image_gen_model_v25()
                                
                                try:
                                    # 2.5 Flash ä¹Ÿæ˜¯ä¼˜å…ˆå°è¯• Text2Imgï¼Œå› ä¸ºå®ƒå¯¹ Img2Img æ”¯æŒä¸€èˆ¬
                                    response_v25 = model_v25.generate_content(
                                        [edit_instruction],
                                        generation_config={"response_modalities": ["IMAGE"]}
                                    )
                                    img_bytes, err_msg = validate_and_process_image(response_v25, "Gemini 2.5 Flash")
                                    
                                    if img_bytes:
                                        st.session_state["step1_image"] = img_bytes
                                        st.success("âœ… 2.5 Flash ç”ŸæˆæˆåŠŸï¼")
                                    else:
                                        st.error(f"âŒ æœ€ç»ˆå¤±è´¥ã€‚\næœ€åæŠ¥é”™: {err_msg}")
                                except Exception as e:
                                    st.error(f"âŒ ç³»ç»Ÿé”™è¯¯: {str(e)}")
                                    
                        except Exception as e:
                            st.error(f"ä¸¥é‡é”™è¯¯: {e}")

    # === å³ä¾§ï¼šé¢„è§ˆä¸ Step 2 ===
    with col2:
        st.subheader("2. é¢„è§ˆä¸ç²¾ä¿® (Hands)")
        
        if st.session_state["step1_image"]:
            try:
                image_stream = io.BytesIO(st.session_state["step1_image"])
                st.image(image_stream, caption="Step 1: Gemini è‰å›¾", use_column_width=True)
                download_image(st.session_state["step1_image"], "step1_draft.jpg", is_bytes=True)
                
                st.divider()
                st.info("ğŸ‘‡ Step 2: Flux ç²¾ä¿®")
                
                flux_prompt = st.text_area("ç²¾ä¿®æŒ‡ä»¤", value="Cinematic lighting, 8k resolution, photorealistic, product photography", height=80)
                strength = st.slider("é‡ç»˜å¹…åº¦", 0.1, 1.0, 0.35)
                
                if st.button("ğŸš€ Flux ç²¾ä¿®", type="primary"):
                    with st.spinner("Flux æ¸²æŸ“ä¸­..."):
                        step1_file = io.BytesIO(st.session_state["step1_image"])
                        output = replicate.run(
                            "black-forest-labs/flux-dev", 
                            input={"prompt": flux_prompt + UNIVERSAL_QUALITY_PROMPT, "image": step1_file, "prompt_strength": 1 - strength, "go_fast": False, "output_quality": 100}
                        )
                        st.image(str(output[0]), use_column_width=True)
                        download_image(str(output[0]), "final.jpg")
            except Exception:
                st.session_state["step1_image"] = None
        else:
            st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§å®Œæˆ Step 1ã€‚")

# ==================================================
# Tab 2-6: å…¶ä»–åŠŸèƒ½åŒº (ä¿æŒä¸å˜)
# ==================================================
with tabs[1]:
    st.header("âœ¨ æ–‡ç”Ÿå›¾")
    # ... (æ–‡ç”Ÿå›¾ä»£ç ä¿æŒä¸€è‡´) ...
    col1, col2 = st.columns([4, 6])
    with col1:
        prompt_text = st.text_area("ç”»é¢æè¿°", height=150)
        if st.button("æ¶¦è‰²"): pass
    with col2:
        if st.button("ç”Ÿæˆ"): pass

with tabs[2]:
    st.header("ğŸ–Œï¸ å±€éƒ¨é‡ç»˜")
    # ... (å±€éƒ¨é‡ç»˜ä»£ç ) ...

with tabs[3]:
    st.header("â†”ï¸ ç”»å¹…æ‰©å±•")
    # ... (æ‰©å±•ä»£ç ) ...

with tabs[4]:
    st.header("ğŸ” é«˜æ¸…æ”¾å¤§")
    # ... (æ”¾å¤§ä»£ç ) ...

with tabs[5]:
    st.header("ğŸ§© A+ åŠ©æ‰‹")
    # ... (åŠ©æ‰‹ä»£ç ) ...

# --- åº•éƒ¨ï¼šæ¨¡å‹è‡ªæ£€å·¥å…· (å¿…ç”¨ï¼) ---
st.markdown("---")
with st.expander("ğŸ” æ¨¡å‹ä½“æ£€å·¥å…· (ç‚¹æ­¤æ’æŸ¥é—®é¢˜)"):
    st.caption("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ï¼ŒæŸ¥çœ‹æ‚¨çš„ API Key åˆ°åº•æ”¯æŒå“ªäº› Gemini æ¨¡å‹ã€‚")
    if st.button("è¿è¡Œæ¨¡å‹è¯Šæ–­"):
        try:
            st.write("æ­£åœ¨è¿æ¥ Google API...")
            models = []
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    models.append(m.name)
            
            st.success(f"æŸ¥è¯¢æˆåŠŸï¼å…±æ‰¾åˆ° {len(models)} ä¸ªå¯ç”¨æ¨¡å‹ï¼š")
            st.code("\n".join(models))
            
            # è‡ªåŠ¨æ£€æµ‹æ˜¯å¦åŒ…å«æˆ‘ä»¬ç”¨åˆ°çš„æ¨¡å‹
            required = ['gemini-3-pro-preview', 'gemini-3-pro-image-preview', 'gemini-2.5-flash-image-preview']
            missing = [r for r in required if f"models/{r}" not in models]
            
            if missing:
                st.error(f"âš ï¸ è­¦å‘Šï¼šæ‚¨çš„è´¦å·ç¼ºå°‘ä»¥ä¸‹æ¨¡å‹æƒé™ï¼Œå¯èƒ½ä¼šå¯¼è‡´æŠ¥é”™ï¼š\n{missing}")
            else:
                st.success("âœ… å®Œç¾ï¼æ‚¨çš„è´¦å·æ‹¥æœ‰æ‰€æœ‰é¡¶çº§æ¨¡å‹çš„æƒé™ã€‚")
                
        except Exception as e:
            st.error(f"è¯Šæ–­å¤±è´¥: {e}")
