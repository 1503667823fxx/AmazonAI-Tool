import streamlit as st
import google.generativeai as genai
from PIL import Image
import io
import time
from collections import deque

# ==========================================
# ğŸ§  æ™ºèƒ½åˆ†ææ ¸å¿ƒ (Smart Analysis Engine) [NEW]
# ==========================================
def smart_analyze_image(model_name, image_file, task_type, user_idea, user_weight, enable_split, translator):
    """
    å°è£…äº†å¤æ‚çš„ Prompt å·¥ç¨‹é€»è¾‘ï¼š
    1. æ¥æ”¶å›¾ç‰‡å’Œç”¨æˆ·éœ€æ±‚
    2. æ ¹æ®æƒé‡ (user_weight) åŠ¨æ€æ„å»º System Prompt
    3. è°ƒç”¨ Vision Model åˆ†æ
    4. å¤„ç†æ‹†åˆ†é€»è¾‘ (|||)
    5. è‡ªåŠ¨ç¿»è¯‘å¹¶è¿”å›ç»“æ„åŒ–æ•°æ® [{'en':..., 'zh':...}]
    """
    try:
        # é‡ç½®æ–‡ä»¶æŒ‡é’ˆï¼Œç¡®ä¿è¯»å–å®Œæ•´
        image_file.seek(0)
        img_obj = Image.open(image_file)
        
        model = genai.GenerativeModel(model_name)
        
        # æ³¨å…¥é«˜è´¨é‡æ‘„å½±æŒ‡ä»¤
        special_instruction = ""
        if "Product Only" in task_type:
            special_instruction = """
            SPECIAL INSTRUCTION FOR PRODUCT PHOTOGRAPHY:
            1. **Layout**: If user implies 'flat lay' or 'break down', use "Knolling photography", "Neatly arranged".
            2. **Realism**: Use "Contact shadows", "Ambient occlusion" to avoid floating look.
            3. **Texture**: Emphasize "fabric texture", "material details".
            """
        
        # æ ¸å¿ƒæƒé‡é€»è¾‘æ³¨å…¥
        weight_instruction = f"""
        WEIGHT CONTROL INSTRUCTION:
        The user has set an influence weight of {user_weight} (Range 0.0 to 1.0).
        - If weight > 0.7: Prioritize the User's Idea ('{user_idea}') completely.
        - If weight < 0.3: Prioritize the Visual Analysis of the image.
        - If weight is 0.4-0.6: Balance both.
        """

        if enable_split:
            prompt_req = f"""
            Role: Art Director. 
            Task: Create detailed prompts based on User Idea and Image. Type: {task_type}.
            {weight_instruction}
            {special_instruction}
            IMPORTANT LOGIC: Split distinct outputs into separate prompts using "|||".
            STRICT OUTPUT FORMAT: Separate prompts with "|||". NO Markdown.
            User Idea: {user_idea}
            Output: English Prompts Only.
            """
        else:
            prompt_req = f"""
            Role: Art Director. 
            Task: Create ONE single, high-quality prompt based on User Idea and Image. Type: {task_type}.
            {weight_instruction}
            {special_instruction}
            STRICT OUTPUT FORMAT: Provide ONE unified prompt. NO "|||". NO Markdown.
            User Idea: {user_idea}
            Output: English Prompt Only.
            """

        response = model.generate_content([prompt_req, img_obj])
        raw_text = response.text.strip()
        
        # è§£æå¹¶ç¿»è¯‘
        prompt_list = raw_text.split("|||")
        result_data = []
        
        for p in prompt_list:
            p_en = p.strip()
            if p_en:
                p_zh = translator.to_chinese(p_en)
                result_data.append({"en": p_en, "zh": p_zh})
        
        return result_data

    except Exception as e:
        st.error(f"æ™ºèƒ½åˆ†ææ¨¡å—å‡ºé”™: {str(e)}")
        return []

# ==========================================
# ğŸ—‚ï¸ å†å²è®°å½•æ ¸å¿ƒ (History Manager)
# ==========================================
class HistoryManager:
    def __init__(self):
        if "history_queue" not in st.session_state:
            st.session_state["history_queue"] = deque(maxlen=20)

    def add(self, image_bytes, source, prompt_summary):
        timestamp = time.strftime("%H:%M")
        unique_id = f"{int(time.time()*1000)}"
        
        st.session_state["history_queue"].appendleft({
            "id": unique_id,
            "image": image_bytes,
            "source": source,
            "time": timestamp,
            "desc": prompt_summary
        })

    def render_sidebar(self):
        with st.expander("ğŸ•’ å†å²è®°å½• (History)", expanded=False):
            if not st.session_state["history_queue"]:
                st.caption("æš‚æ— ç”Ÿæˆè®°å½•")
                return

            for item in st.session_state["history_queue"]:
                col_thumb, col_info = st.columns([1, 2])
                with col_thumb:
                    # ç¡®ä¿è¿™é‡Œè°ƒç”¨æ­£ç¡®
                    thumb = create_preview_thumbnail(item['image'], max_width=150)
                    st.image(thumb, use_container_width=True)
                with col_info:
                    st.caption(f"**{item['source']}**")
                    st.caption(f"_{item['desc'][:15]}..._")
                    
                    b1, b2 = st.columns(2)
                    with b1:
                        if st.button("ğŸ”", key=f"h_zoom_{item['id']}"):
                            show_preview_modal(item['image'], item['source'])
                    with b2:
                        final_bytes, mime = process_image_for_download(item['image'], format="JPEG")
                        st.download_button("ğŸ“¥", data=final_bytes, file_name=f"hist_{item['id']}.jpg", mime=mime, key=f"h_dl_{item['id']}")
                st.divider()

# ==========================================
# ğŸ› ï¸ å›¾ç‰‡å¤„ç†æ ¸å¿ƒ (Image Engine)
# ==========================================
@st.cache_data(show_spinner=False)
def process_image_for_download(image_bytes, format="PNG", quality=95):
    try:
        if not image_bytes: return None, None
        image = Image.open(io.BytesIO(image_bytes))
        buf = io.BytesIO()
        target_format = format.upper()
        mime_type = f"image/{target_format.lower()}"

        if target_format == "JPEG":
            if image.mode in ("RGBA", "P"): image = image.convert("RGB")
            image.save(buf, format="JPEG", quality=quality)
        else:
            image.save(buf, format="PNG")
        
        return buf.getvalue(), mime_type
    except Exception:
        return image_bytes, "image/png"

@st.cache_data(show_spinner=False)
def create_preview_thumbnail(image_bytes, max_width=800):
    try:
        image = Image.open(io.BytesIO(image_bytes))
        if image.width > max_width:
            ratio = max_width / image.width
            new_height = int(image.height * ratio)
            image = image.resize((max_width, new_height), Image.Resampling.LANCZOS)
        
        buf = io.BytesIO()
        if image.mode in ("RGBA", "P"): image = image.convert("RGB")
        image.save(buf, format="JPEG", quality=70)
        return buf.getvalue()
    except:
        return image_bytes

def show_preview_modal(image_bytes, caption):
    # ç®€å•çš„æ¨¡æ€æ¡†æ¨¡æ‹Ÿ
    st.toast(f"æ­£åœ¨å…¨å±é¢„è§ˆ: {caption}")
    st.image(image_bytes, caption=caption, use_container_width=True)

# ==========================================
# ğŸ—£ï¸ ç¿»è¯‘æ ¸å¿ƒ (Translation Engine)
# ==========================================
class AITranslator:
    def __init__(self):
        if "GOOGLE_API_KEY" in st.secrets:
            genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
            self.model = genai.GenerativeModel("models/gemini-flash-latest")
            self.valid = True
        else:
            self.valid = False

    def to_chinese(self, text):
        if not text or not self.valid: return text
        return self._run(text, "Simplified Chinese")

    def to_english(self, text):
        if not text or not self.valid: return text
        return self._run(text, "English")

    def _run(self, text, lang):
        try:
            prompt = f"Translate to {lang}. Output ONLY the translation. Text: {text}"
            resp = self.model.generate_content(prompt)
            return resp.text.strip()
        except:
            return text
