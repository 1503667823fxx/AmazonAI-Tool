import streamlit as st
import google.generativeai as genai
from services.styles import PRESETS

class LLMEngine:
    def __init__(self, api_key=None):
        self.api_key = api_key or st.secrets.get("GOOGLE_API_KEY")
        if self.api_key:
            genai.configure(api_key=self.api_key)
            self.valid = True
        else:
            self.valid = False
            
    def translate(self, text, target_lang="English"):
        if not text or not self.valid: return text
        try:
            model = genai.GenerativeModel("models/gemini-flash-latest")
            prompt = f"Translate to {target_lang}. Output ONLY translation. Text: {text}"
            resp = model.generate_content(prompt)
            return resp.text.strip()
        except: return text

    def analyze_image_style(self, image, prompt_instruction):
        if not self.valid: return "Error"
        try:
            model = genai.GenerativeModel("models/gemini-flash-latest")
            resp = model.generate_content([prompt_instruction, image])
            return resp.text.strip()
        except Exception as e: return str(e)

    def optimize_art_director_prompt(self, user_idea, task_type, user_weight, style_key, image_input=None, enable_split=False):
        """
        V4 å¼ºåŠ›æ„å›¾ç†è§£ç‰ˆï¼š
        è§£å†³â€œå¬ä¸æ‡‚äººè¯â€çš„é—®é¢˜ã€‚å¼ºåˆ¶ AI å°†ç”¨æˆ·çš„æŠ½è±¡ä¿®æ”¹è¦æ±‚ï¼ˆå¦‚â€˜æ¢æˆå¥½è±åæ¨¡ç‰¹â€™ï¼‰
        è½¬åŒ–ä¸ºå…·ä½“çš„è§†è§‰æè¿°ï¼ˆå¦‚â€˜Caucasian female, blonde hair, western facial featuresâ€™ï¼‰ï¼Œ
        ä»è€Œåœ¨ç”Ÿå›¾æ—¶è¦†ç›–åŸå›¾çš„ç‰¹å¾ã€‚
        """
        if not self.valid: return []

        # 1. è·å–é£æ ¼æ•°æ®
        style_data = PRESETS.get(style_key, PRESETS["ğŸ’¡ é»˜è®¤ (None)"])
        style_desc = style_data["desc"]

        # 2. æ„å»ºè¾“å…¥æ•°æ®
        inputs = []
        img_context = ""
        if image_input:
            if isinstance(image_input, list):
                inputs.extend(image_input)
                img_context = f"provided {len(image_input)} reference images"
            else:
                inputs.append(image_input)
                img_context = "provided 1 reference image"

        # 3. æ„å»º CoT (æ€ç»´é“¾) ç³»ç»ŸæŒ‡ä»¤
        # æ ¸å¿ƒæ”¹åŠ¨ï¼šè¦æ±‚ AI å…ˆæ£€æµ‹å†²çªï¼Œå†é‡å†™æè¿°
        system_prompt = f"""
        Role: Senior Visual Prompt Engineer.
        
        ã€Goalã€‘
        Transform the User's Request into a HIGHLY DESCRIPTIVE English prompt for image generation.
        You are looking at {img_context}.
        
        ã€User Requestã€‘: "{user_idea}"
        ã€Target Styleã€‘: "{style_key}" ({style_desc})
        
        ã€CRITICAL THINKING PROCESSã€‘
        1. **ANALYZE DELTA**: Compare User Request vs. Reference Image. 
           - Does user want to change the Subject? (e.g. "change model", "swap into dog")
           - Does user want to change the Background? (e.g. "at a party", "on beach")
           - Does user want to change the Clothes?
           
        2. **OVERRIDE RULE (The most important rule)**: 
           - If user asks to CHANGE something, you MUST describe the NEW element in EXTREME DETAIL.
           - Example: User says "Hollywood Model". You write: "A glamorous Hollywood supermodel, Caucasian female, American facial features, blonde wavy hair, blue eyes, confident smile, western aesthetic." 
           - **DO NOT** just say "Hollywood model". The AI needs VISUAL ADJECTIVES to override the reference image.
           
        3. **COMPOSITION**: Keep the pose/composition from reference image unless told otherwise.

        ã€Output Formatã€‘
        - Output ONLY the final English prompt string. 
        - Include high quality tags: 8k, photorealistic, masterpiece, {style_desc}.
        - Do not output explanations.
        """
        
        inputs.insert(0, system_prompt)

        try:
            model = genai.GenerativeModel("models/gemini-1.5-flash") # å»ºè®®ä½¿ç”¨ 1.5 flashï¼Œç†è§£åŠ›æ›´å¥½
            
            # è®¾ç½®ç”Ÿæˆé…ç½®ï¼Œé™ä½éšæœºæ€§ï¼Œæé«˜éµä»åº¦
            config = genai.types.GenerationConfig(
                temperature=0.4, 
                candidate_count=1
            )
            
            response = model.generate_content(inputs, generation_config=config)
            raw_text = response.text.strip()
            
            # æ¸…ç†å¯èƒ½äº§ç”Ÿçš„ markdown æ ¼å¼
            final_prompt = raw_text.replace("```text", "").replace("```", "").strip()
            
            return [final_prompt]
            
        except Exception as e:
            print(f"Prompt Optimization Error: {e}")
            # é™çº§å¤„ç†ï¼šç®€å•çš„æ‹¼æ¥
            return [f"{user_idea}, {style_desc}, high quality, 8k"]
