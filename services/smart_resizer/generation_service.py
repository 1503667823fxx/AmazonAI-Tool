import streamlit as st
import google.generativeai as genai
from PIL import Image
import io

# åˆå§‹åŒ– API
API_KEY = st.secrets.get("GOOGLE_API_KEY") or st.secrets["google"]["api_key"]
genai.configure(api_key=API_KEY)

def analyze_image_composition(image: Image.Image) -> dict:
    """
    ä½¿ç”¨Geminiåˆ†æžå›¾ç‰‡æž„å›¾å’Œä¸»ä½“ä½ç½®
    """
    try:
        model = genai.GenerativeModel('models/gemini-1.5-pro')
        
        analysis_prompt = """Analyze this product image composition and provide detailed information:

1. Main subject identification:
   - What is the main product/subject in the image?
   - Where is it positioned (center, left, right, top, bottom)?
   - What percentage of the image does it occupy?

2. Background analysis:
   - What type of background (solid color, gradient, textured, scene)?
   - What colors are dominant in the background?
   - Is the background simple or complex?

3. Composition recommendations:
   - For different aspect ratios (1:1, 4:3, 21:9), how should the subject be repositioned?
   - What background extension would work best?
   - Should the subject be scaled or just repositioned?

Please provide a structured analysis in JSON format with keys: subject_position, subject_size_percent, background_type, background_colors, composition_recommendations."""
        
        response = model.generate_content([analysis_prompt, image])
        
        if response.text:
            # å°è¯•è§£æžJSONå“åº”ï¼Œå¦‚æžœå¤±è´¥åˆ™è¿”å›žåŸºæœ¬åˆ†æž
            try:
                import json
                analysis = json.loads(response.text)
                return analysis
            except:
                # å¦‚æžœJSONè§£æžå¤±è´¥ï¼Œè¿”å›žæ–‡æœ¬åˆ†æž
                return {"analysis_text": response.text}
        
        return {"error": "No analysis received"}
        
    except Exception as e:
        st.warning(f"å›¾ç‰‡åˆ†æžå¤±è´¥: {str(e)}")
        return {"error": str(e)}

def fill_image(image: Image.Image, mask: Image.Image, prompt: str, use_gemini: bool = True, target_ratio: tuple = None, test_mode: bool = False, composition_mode: str = "æ™ºèƒ½åˆ†æž", quality_level: str = "æ ‡å‡†", background_handling: str = "æ™ºèƒ½å»¶ç»­") -> Image.Image:
    """
    æ™ºèƒ½çš„Geminiç”»å¹…é‡æž„ - è€ƒè™‘ä¸»ä½“ä½ç½®å’Œæž„å›¾ä¼˜åŒ–
    """
    try:
        if target_ratio:
            ratio_w, ratio_h = target_ratio
            target_ratio_val = ratio_w / ratio_h
            orig_w, orig_h = image.size
            orig_ratio = orig_w / orig_h
            
            # é¦–å…ˆåˆ†æžå›¾ç‰‡æž„å›¾
            st.write("ðŸ” æ­£åœ¨åˆ†æžå›¾ç‰‡æž„å›¾...")
            composition_analysis = analyze_image_composition(image)
            
            # æ ¹æ®åˆ†æžç»“æžœè°ƒæ•´æç¤ºè¯
            model = genai.GenerativeModel('models/gemini-1.5-pro-vision-latest')
            
            # æ ¹æ®ç”¨æˆ·é€‰æ‹©æž„å»ºæ™ºèƒ½æç¤ºè¯
            if target_ratio_val > orig_ratio:
                expansion_direction = "horizontally (width)"
                positioning_advice = "reposition the main subject optimally for wider composition"
            elif target_ratio_val < orig_ratio:
                expansion_direction = "vertically (height)"
                positioning_advice = "maintain subject prominence while adding appropriate vertical content"
            else:
                expansion_direction = "minimally"
                positioning_advice = "optimize the composition slightly"
            
            # æž„å›¾æ¨¡å¼æŒ‡ä»¤
            composition_instructions = {
                "æ™ºèƒ½åˆ†æž": "Analyze the subject position and reposition it optimally for the new aspect ratio. The subject should be placed where it looks most natural and balanced.",
                "ä¿æŒå±…ä¸­": "Keep the main subject centered in the new composition.",
                "è‡ªå®šä¹‰ä½ç½®": "Position the subject according to the rule of thirds for professional composition."
            }
            
            # è´¨é‡çº§åˆ«æŒ‡ä»¤
            quality_instructions = {
                "å¿«é€Ÿ": "Generate efficiently while maintaining good quality.",
                "æ ‡å‡†": "Balance quality and processing time for professional results.",
                "é«˜è´¨é‡": "Prioritize maximum quality, detail preservation, and seamless blending."
            }
            
            # èƒŒæ™¯å¤„ç†æŒ‡ä»¤
            background_instructions = {
                "æ™ºèƒ½å»¶ç»­": "Intelligently extend the existing background patterns, textures, and colors naturally.",
                "æ¨¡ç³Šå»¶ç»­": "Extend the background with a subtle blur effect to create depth.",
                "çº¯è‰²å¡«å……": "Fill new areas with a clean, solid color that complements the existing background."
            }
            
            smart_prompt = f"""Transform this product image to {ratio_w}:{ratio_h} aspect ratio with intelligent recomposition:

TASK: Smart image recomposition and outpainting
- Target aspect ratio: {ratio_w}:{ratio_h} (expand {expansion_direction})
- Current ratio: {orig_ratio:.2f} â†’ Target: {target_ratio_val:.2f}

COMPOSITION STRATEGY:
{composition_instructions[composition_mode]}

BACKGROUND HANDLING:
{background_instructions[background_handling]}

QUALITY LEVEL:
{quality_instructions[quality_level]}

CORE REQUIREMENTS:
1. PRESERVE the main product/subject completely - no cropping
2. INTELLIGENTLY REPOSITION the subject for optimal composition in new aspect ratio
3. SCALE the subject appropriately if beneficial (slightly larger for wider formats)
4. EXTEND background areas seamlessly and naturally
5. {positioning_advice}
6. Maintain original lighting, shadows, and depth
7. Ensure the subject remains the clear focal point
8. Create professional, commercial-grade quality

CRITICAL: The subject should be repositioned and potentially resized to look natural and well-composed in the {ratio_w}:{ratio_h} format, not just placed in expanded canvas."""
            
            st.write(f"ðŸŽ¨ æ­£åœ¨è¿›è¡Œæ™ºèƒ½é‡æž„ (ç›®æ ‡æ¯”ä¾‹: {ratio_w}:{ratio_h})...")
            
            response = model.generate_content([smart_prompt, image])
            
            if response.parts:
                for part in response.parts:
                    if hasattr(part, "inline_data") and part.inline_data:
                        img_data = part.inline_data.data
                        result_image = Image.open(io.BytesIO(img_data))
                        
                        # éªŒè¯ç»“æžœ
                        gen_w, gen_h = result_image.size
                        gen_ratio = gen_w / gen_h
                        
                        # æ£€æŸ¥æ¯”ä¾‹æ˜¯å¦æŽ¥è¿‘ç›®æ ‡
                        ratio_diff = abs(gen_ratio - target_ratio_val)
                        if ratio_diff < 0.1:  # å…è®¸10%çš„è¯¯å·®
                            st.success(f"âœ… æ™ºèƒ½é‡æž„æˆåŠŸï¼")
                            st.info(f"ðŸ“ å°ºå¯¸å˜åŒ–: {orig_w}Ã—{orig_h} â†’ {gen_w}Ã—{gen_h}")
                            st.info(f"ðŸ“ æ¯”ä¾‹å˜åŒ–: {orig_ratio:.2f} â†’ {gen_ratio:.2f} (ç›®æ ‡: {target_ratio_val:.2f})")
                            
                            # æ˜¾ç¤ºæž„å›¾åˆ†æžç»“æžœ
                            if "analysis_text" in composition_analysis:
                                with st.expander("ðŸŽ¯ æž„å›¾åˆ†æž"):
                                    st.text(composition_analysis["analysis_text"])
                            
                            return result_image
                        else:
                            st.warning(f"âš ï¸ æ¯”ä¾‹åå·®è¾ƒå¤§: ç”Ÿæˆæ¯”ä¾‹ {gen_ratio:.2f}, ç›®æ ‡æ¯”ä¾‹ {target_ratio_val:.2f}")
                            return result_image
            
            # æ£€æŸ¥æ–‡æœ¬å“åº”
            if response.text:
                st.warning(f"Geminiè¿”å›žæ–‡æœ¬å“åº”: {response.text}")
        
        # å¦‚æžœå¤±è´¥ï¼Œè¿”å›žåŽŸå›¾
        st.error("æ™ºèƒ½é‡æž„å¤±è´¥ï¼Œè¿”å›žåŽŸå›¾")
        return image
        
    except Exception as e:
        st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        return image
